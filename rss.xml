<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Layer5 Technical Posts]]></title><description><![CDATA[Expect more from your infrastructure. Cloud native, open source software for your cloud native infrastructure and applications. Allowing developers to focus on business logic, not infrastructure concerns. Empowering operators to confidentally run modern infrastructure.]]></description><link>https://layer5.io</link><generator>GatsbyJS</generator><lastBuildDate>Sun, 23 Oct 2022 15:11:02 GMT</lastBuildDate><item><title><![CDATA[Service Mesh: Istio]]></title><description><![CDATA[Explanation of Istio]]></description><link>https://layer5.io/resources/service-mesh/service-mesh-istio</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/service-mesh-istio</guid><dc:creator><![CDATA[Deepesha Burse]]></dc:creator><pubDate>Wed, 31 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/731763d720780a49c2ffdfede8c28f4b/istio.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;p&gt; Microservice architectures offer some solutions while posing new ones. Application division into separate services makes scaling, updating, and development easier. It also provides you with a lot more moving pieces to connect and secure. It can get quite complicated to manage all of the network services, including load balancing, traffic management, authentication and authorisation, etc. &lt;/p&gt;&lt;p&gt; Istio, an open-source service mesh created by Google, IBM, and Lyft, enables you to connect, monitor, and secure microservices that are hosted on-premises, in the cloud, or with orchestration systems like Kubernetes and Mesos. The beta version of Istio was announced in the year 2018 in KubeCon on Google Cloud. &lt;/p&gt;&lt;p&gt; Before moving on to what Istio is and how it works, let us look into what service meshes are and why there was an urgent need for them as microservices started getting used more. &lt;/p&gt;&lt;h3&gt; Service Mesh &lt;/h3&gt;&lt;p&gt; A service mesh is an infrastructural layer that is used to provide secure communication between different services for on-prem, cloud or multi-cloud infrastructure. It allows us to add features like observability, traffic management, and security without having to add that to our code. The term &amp;quot;service mesh&amp;quot; refers to both the kind of software you employ to carry out this pattern and the security or network domain that results from its application. &lt;/p&gt;&lt;p&gt; Service meshes are divided into two parts: the control plane and the data plane. The control plane&amp;#x27;s responsibilities include securing the mesh, facilitating service discovery, doing regular health checks, enforcing policies, and handling other operational issues. A central registration of services and their corresponding IP addresses is referred to as service discovery. To share with other services how to communicate with it and to assist enforce rules on which services are allowed to communicate with which other services, the application must be registered on the control plane. &lt;/p&gt;&lt;p&gt; The communication between services, on the other hand, is handled by the data plane. Because many service mesh solutions use a sidecar proxy to manage data plane connections, the amount of knowledge that the services must have about the network environment is constrained. &lt;/p&gt;&lt;img src=&quot;static/service-mesh-609aa147db2609960150f75fb05ab088.svg&quot; class=&quot;image-center&quot; alt=&quot;Service Mesh&quot;/&gt;&lt;h3&gt; Inside the Istio service mesh &lt;/h3&gt;&lt;p&gt; A data plane and a control plane are logically separate parts of an Istio service mesh.&lt;ul&gt;&lt;li&gt; A group of intelligent proxies (Envoy) that are deployed as sidecars make up the data plane. All network connection among the microservices is mediated and managed by these proxies. Additionally, they gather and compile data on all mesh communications. &lt;/li&gt;&lt;li&gt; The proxies are controlled and set up by the control plane to route traffic. &lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;&lt;img src=&quot;static/arch-040603070065c5c8a1013a81573f9981.svg&quot; class=&quot;image-center&quot; alt=&quot;Istio Service Mesh Architecture&quot;/&gt;&lt;h4&gt; Envoy &lt;/h4&gt;&lt;p&gt; The data plane of Istio consists of the Envoy sidecar proxy. Envoy is an edge and service proxy that is open source and free that aids in separating network concerns from core applications. Applications don&amp;#x27;t care about the network topology; they just transmit and receive messages to and from localhost. Envoy is fundamentally a network proxy that operates at the OSI model&amp;#x27;s L3 and L4 layers. It operates by processing connections through a series of pluggable network filters. Envoy additionally provides support for an extra L7 layer filter for HTTP-based traffic. Envoy also offers excellent support for the HTTP/2 and gRPC transports. &lt;/p&gt;&lt;p&gt; Many of the features provided by Istio such as security, traffic control, network resiliency are possible due to Envoy. &lt;/p&gt;&lt;h4&gt; Istiod &lt;/h4&gt;&lt;p&gt; Service discovery, configuration, and certificate management are offered by Istiod. &lt;/p&gt;&lt;p&gt; High level routing rules that govern traffic behavior are transformed into Envoy-specific configurations by Istiod and propagated to the sidecars during runtime. Any sidecar that complies with the Envoy API can use Pilot, which synthesizes platform-specific service discovery techniques into an abstract form. &lt;/p&gt;&lt;p&gt; Istio can handle discovery in a variety of settings, including Kubernetes or virtual machines. &lt;/p&gt;&lt;p&gt; To exert finer control over the traffic in your service mesh, you can ask Istiod to modify the Envoy configuration using the Traffic Management API. &lt;/p&gt;&lt;p&gt; Strong service-to-service and end-user authentication are made possible by Istiod security&amp;#x27;s integrated identity and credential management. Istio can be used to enhance unencrypted service mesh traffic. &lt;/p&gt;&lt;p&gt; Operators can enforce regulations with Istio based on service identity rather than on layer 3 or layer 4 network IDs, which are more prone to instability. Additionally, you can limit who has access to your services by using Istio&amp;#x27;s authorisation capability. &lt;/p&gt;&lt;p&gt; In order to enable secure mTLS connection in the data plane, Istiod performs the role of a Certificate Authority (CA) and issues certificates. &lt;/p&gt;&lt;h3&gt; Features &lt;/h3&gt;&lt;h4&gt; Traffic Management &lt;/h4&gt;&lt;p&gt; Performance is impacted by traffic routing, both within and across clusters, which improves deployment strategy. You can simply manage the flow of traffic and API requests between services using Istio&amp;#x27;s traffic routing rules. Istio makes it simple to configure critical activities like A/B testing, canary deployments, and staged rollouts with percentage-based traffic divides, as well as service-level attributes like circuit breakers, timeouts, and retries. &lt;/p&gt;&lt;h4&gt; Observability &lt;/h4&gt;&lt;p&gt; It becomes harder to comprehend behaviour and performance as services become more complicated. Istio produces comprehensive telemetry for each communication taking place within a service mesh. This telemetry makes service activity observable, enabling operators to maintain, optimise, and debug their applications. Even better, you can implement practically all of this instrumentation without making any changes to your applications. Operators are able to fully comprehend how the monitored services are communicating with Istio. &lt;/p&gt;&lt;p&gt; Detailed metrics, distributed traces, and complete access logs are all included in Istio&amp;#x27;s telemetry. You get complete and thorough service mesh observability with Istio. &lt;/p&gt;&lt;h4&gt; Security Capabilities &lt;/h4&gt;&lt;p&gt; Particular security requirements for microservices include defense against man-in-the-middle attacks, adaptable access rules, auditing tools, and mutual TLS. Istio comes with a comprehensive security solution that enables administrators to handle each of these problems. To safeguard your services and data, it offers strong identity, strong policy, transparent TLS encryption, and authentication, authorization, and audit (AAA) tools. &lt;/p&gt;&lt;p&gt; The security architecture used by Istio is built on security-by-default, and it aims to provide in-depth defense so you may deploy security-conscious apps even across networks with a low level of trust. &lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[The Ultimate List of Open Source Cloud-Native Tools]]></title><link>https://layer5.io/company/news/the-ultimate-list-of-open-source-cloud-native-tools</link><guid isPermaLink="false">https://layer5.io/company/news/the-ultimate-list-of-open-source-cloud-native-tools</guid><dc:creator><![CDATA[Bill Doerrfeld]]></dc:creator><pubDate>Mon, 29 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/518e9c75ae1584673318e9d69c4b367a/tools.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 lbnsvn&quot;&gt;&lt;div class=&quot;test&quot;&gt;&lt;p&gt;There are so many great open source cloud-native tools for nearly everything you want to do.
And they’re all in one place—look no further than the Cloud Native Computing Foundation (CNCF).This Linux Foundation body has become a locus of some stellar cloud-native open source projects. The CNCF now hosts an array of helpful packages, spanning container scheduling, observability, persistent storage, container runtime and other areas.&lt;/p&gt;&lt;p&gt;Odds are the cloud-native DevOps tool you need has already been developed—it’s only a matter of finding it. In recent posts, we highlighted many CNCF tools across various areas. Below, we’ll gloss over each category from a birds-eye view. Click each headline for the full rundown, or read below for a summary of the tools in each category.&lt;/p&gt;&lt;h3&gt;Scheduling  Orchestration&lt;/h3&gt;&lt;br/&gt;Kubernetes is the most popular container scheduling tool. It can be used to automate the deployment and management of multi-cloud applications. Other scheduling and orchestration utilities from CNCF include Crossplane, Fluid, Karmada, kube-rs, Open Cluster Management and Volcano.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Observability and Analysis&lt;/h3&gt;&lt;br/&gt;Prometheus tops the list of observability and analysis tools. The platform can be used to power your monitoring and alerting systems with fine-grained metrics and excellent querying capabilities. Other CNCF tools for observability and analysis include Jaeger, Fluentd, Thanos, Cortex and OpenTelemetry.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Security and Compliance&lt;/h3&gt;&lt;br/&gt;Open Policy Agent (OPA) can be used to unify cloud-native policies across the cloud-native stack. OPA uses a common language to express authorization policies and provides a policy engine to make authorization decisions. Other CNCF projects that deliver security-as-code include The Update Framework (TUF), Falco, Notary, cert-manager and Curiefense.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;CI/CD&lt;/h3&gt;&lt;br/&gt;Argo is a suite of packages that help direct jobs on Kubernetes to aid a continuous delivery pipeline. Using Argo, developers can create multi-step custom workflows and share these workflows across a cluster. Other CI/CD tools hosted by CNCF include Flux, Brigade, Keptn, OpenGitOps and OpenKruise.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Service Mesh Tools&lt;/h3&gt;&lt;br/&gt;Linkerd is a highly performant developer-favorite service mesh comprised of a control plane to apply configurations and a data plane that deploys its own unique proxy. This proxy can apply consistent security, observability, monitoring and telemetry features across distributed microservices. Other service mesh tools from CNCF include Kuma, Open Service Mesh (OSM), &lt;a href=&quot;/projects/service-mesh-interface-conformance&quot;&gt;Service Mesh Interface (SMI) &lt;/a&gt; , &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt; and &lt;a href=&quot;/projects/service-mesh-performance&quot;&gt;Service Mesh Performance(SMP)&lt;/a&gt;.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Service Proxies&lt;/h3&gt;&lt;br/&gt;Envoy is a service proxy commonly used within service meshes like Istio and Kuma. Envoy is intended to run alongside applications to help standardize networking and observability within large microservices networks. Other service proxy projects include Contour BFE and OpenELB.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Persistent Storage&lt;/h3&gt;&lt;br/&gt;Rook is a tool that helps automate away some of the pains of managing cloud-native persistent storage. Rook supports file, block and object storage types and can be used for programmatic storage, migration, disaster recovery, monitoring and resource management. Other cloud-native persistent storage projects include Longhorn, CubeFS, K8up, OpenEBS, ORAS, Piraeus Datastore and Vineyard.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Cloud-Native Database Tools&lt;/h3&gt;&lt;br/&gt;TiKV is a unified distributed storage layer that can process large amounts of data. The project supports a key-value API and has rapid response times. Other cloud-native database utilities include Vitess, a clustering system for horizontal scaling of MySQL and SchemaHero, a Kubernetes operator for declarative database schema management.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Container Runtime&lt;/h3&gt;&lt;br/&gt;Containerd is an industry-standard container runtime supported by most container-based systems. Originally built as part of Docker, containerd was donated to the Linux Foundation in 2015. Other notable CNCF container runtime utilities include CRI-O, Inclavare Containers and WasmEdge Runtime.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;App Definition and Build Tools&lt;/h3&gt;&lt;br/&gt;Helm is a prevalent Kubernetes package manager widely used to share a manifest of dependencies. Operators often use Helm charts to find and install third-party applications. Other notable tools which help address operational concerns of Kubernetes include Buildpacks, KubeVirt, Operator Framework and Backstage.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Cloud-Native Networking&lt;/h3&gt;&lt;br/&gt;Cilium is a tool that brings eBPF-based networking, security and observability. Cilium helps build out networking between container workloads and cross-cluster connectivity. Additional cloud-native networking utilities include Antrea, CNI-Genie, Kube-OVN, Network Service Mesh (NSM) and Submariner. There’s also the Container Network Interface (CNI), an interface specification for container networking.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Streaming and Messaging&lt;/h3&gt;&lt;br/&gt;CloudEvents offers a specification intended to help standardize the event-based communication from various event publisher systems. By having a way to describe events consistently, developers could solve interoperability issues. Other CNCF streaming and messaging projects include NATS, Pravega, Strimzi and Tremor.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Chaos Engineering&lt;/h3&gt;&lt;br/&gt;Chaos Mesh is a chaos engineering platform for Kubernetes. Using Chaos Mesh, operators can push their Kubernetes deployments to the limit with stress testing, fault injections, and other testing behaviors. You can also schedule routine tests. Other cloud-native chaos testing tools from CNCF include Litmus and ChaosBlade.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Key Management&lt;/h3&gt;&lt;br/&gt;SPIFFE is defined as a universal identity control plane for a distributed architecture. Using SPIFFE, engineers can quickly construct a standard method to identify workloads and automatically secure service-to-service communication. SPIRE is the product-ready reference implementation of SPIFFE. Other key management tools from CNCF include Athenz and Teller.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Edge Computing and Bare Metal&lt;/h3&gt;&lt;br/&gt;KubeEdge helps extend cloud-native capabilities into edge computing. It’s specifically designed with the constraints of edge nodes in mind, such as reliability and resource limitations. Other projects that help extend Kubernetes to the edge include Akri, OpenYurt and SuperEdge. Other tools aid in provisioning K8s on bare metal, such as Metal3.io and Tinkerbell.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;The Forecast Looks Cloud-Native&lt;/h3&gt;&lt;br/&gt;By 2023, the &lt;a href=&quot;https://containerjournal.com/features/majority-of-apps-will-use-cloud-native-development-by-2023/&quot;&gt;majority of applications will be cloud-native&lt;/a&gt;. The cloud-native world is here to stay, and open source is the foundation to support our new era of microservices, containerization and DevOps.&lt;p&gt;Although you could technically self-host your way through development and operations using these open source projects, organizations will most likely adopt a blend of open source, proprietary and as-a-service cloud offerings to get the job done. Regardless, it’s cool to know what’s available for free use.&lt;/p&gt;&lt;p&gt;It should also be mentioned that tools change from time to time. As such, you can always view the up-to-date CNCF landscape here. Stay tuned as we keep an eye on CNCF and related bodies that continue to carry the cloud-native torch forward!&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[DevOps Adoption: Identifying the Right Metrics]]></title><link>https://layer5.io/resources/devops/devops-adoption-identifying-the-right-metrics</link><guid isPermaLink="false">https://layer5.io/resources/devops/devops-adoption-identifying-the-right-metrics</guid><pubDate>Tue, 23 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/a2819b9ad130794ff7e748bcf7537899/devops-adoption.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;p&gt;According to Puppet’s State of DevOps Report 2021, 83% of IT professionals report that their organizations have previously implemented DevOps practices or are doing so right now to unlock higher business value, achieve faster time to delivery, and boost security of systems.&lt;/p&gt;&lt;p&gt;However, DevOps teams from many industries frequently struggle to identify the right metrics to monitor and measure success. In this &lt;a href=&quot;/static/devops-adoption-choosing-the-right-metrics-a064d95e7d0e37af18817d28b58ef4ff.pdf&quot;&gt;infographic&lt;/a&gt;, we highlight the metrics all DevOps professionals should measure to:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Identify places in the pipeline to speed up deployments.&lt;/li&gt;&lt;li&gt;Make data-driven decisions to improve the deployment process.&lt;/li&gt;&lt;li&gt;Analyze the speed at which products are reaching the market in comparison to competitors.&lt;/li&gt;&lt;/ul&gt;&lt;h3 style=&quot;margin-top:1rem&quot;&gt;Monitor these 5 metrics to understand how to speed up your DevOps toolchain:&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Deployment Time&lt;/li&gt;&lt;li&gt;Change Failure Rate&lt;/li&gt;&lt;li&gt;Recovery Time&lt;/li&gt;&lt;li&gt;Release Cadence&lt;/li&gt;&lt;li&gt;Lead Time&lt;/li&gt;&lt;/ul&gt;&lt;a href=&quot;/static/devops-adoption-choosing-the-right-metrics-a064d95e7d0e37af18817d28b58ef4ff.pdf&quot;&gt;&lt;img src=&quot;static/devops-adoption-c302fe6ec5ec33186ca65d846ae9fd4e.png&quot; alt=&quot;Right metrics for adopting DevOps&quot;/&gt;&lt;/a&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[What is GitOps?]]></title><link>https://layer5.io/resources/cloud-native/what-is-gitops</link><guid isPermaLink="false">https://layer5.io/resources/cloud-native/what-is-gitops</guid><pubDate>Tue, 16 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/a8d747801f0e266dbc9bb2b192cd3dc1/github-dark.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;p&gt;GitOps revolves around the central notion that infrastructure can be treated as code. It is an operational framework that incorporates DevOps best practices for infrastructure automation, including version control, collaboration, compliance, and CI/CD tooling, which are often used for application development. Like code, not only can you store your infrastructure configuration in a source code version system, but you can also take your infrastructure configuration and any changes to its configuration through the same change management process that you do when updating your applications and services. In part, GitOps is about change management, and consequently, it is about risk reduction and risk management. When you automate a process and classify the manner in which you systemize the process, risk is reduced through the consistency and series of processes and reviews changes go through.&lt;/p&gt;&lt;p&gt;GitOps is the acknowledgement that declarative systems that everything is (or should be) defined as code. With all code in a source code system, that system becomes the source of truth and in the system of record for how your infrastructure is running. Well, that is, assuming that your infrastructure configuration hasn&amp;#x27;t drifted from its desired state defined in your source code system. If Git is the source of truth, you cannot run operations manually by executing random commands. Doing so would mean that Git would stop being the only source of truth. Instead, the only goal of operations is to define the desired state as code and store it in git. Then, let the machines synchronize that with the actual state. Such synchronization must be continuous so that the two states are (almost) always in sync. In other words, GitOps is about defining everything as code, storing that code in Git, and letting the machines detect the drift between the desired and the actual state – and making sure that drifts are resolved as soon as possible, hence resulting in the two states being almost always in sync.&lt;/p&gt;&lt;h2&gt; Principles of GitOps&lt;/h2&gt;&lt;h3&gt; 1) Declarative&lt;/h3&gt;&lt;p&gt; According to this principle, the entire system should have a declarative description. Let us first understand what a system description is. What is committed to your Git repository is called the System Description. One or more files that define each system component and its state will be included in the system description. According to GitOps, the way in which we store those definitions is crucial, and we must do so declaratively. That implies that the description of our system will be saved as data.&lt;/p&gt;&lt;p&gt; In the declarative approach, we specify how we want the system to look not how we can achieve that state. If we want to make any changes, we change the description instead of the series of steps to get there. Declarative configuration is critical for GitOps because it provides a description of the system that an automated agent can understand and utilize to take action.&lt;/p&gt;&lt;h3&gt; 2) Single Source of Truth&lt;/h3&gt;&lt;p&gt; The second principle mandates that we keep that system description inside of Git. Therefore, we decide to maintain the official blueprints, which outline the ideal system state version in Git. A git commit is required if we wish to modify the blueprint. The blueprint can also be called the desired state. This helps developers, testers, operations, security, and automations to have a single reference and keep uniformity in everyone’s vision.&lt;/p&gt;&lt;p&gt; GitOps also improves a system&amp;#x27;s ability to recover from failure because it&amp;#x27;s simple to roll back an unsuccessful change or restore the entire system from the repository.&lt;/p&gt;&lt;h3&gt; 3) Automated Change Delivery&lt;/h3&gt;&lt;p&gt; Only automation allows us to apply modifications made to the blueprint to systems already in operation. Delivery of changes is entirely automatic. GitOps doesn&amp;#x27;t allow manual editing. Because standard workflows only need GitHub, which is such a well-known platform, automation enables changes to be delivered through simpler for developers to use workflows. Additionally, automation standardizes your delivery processes, improving the predictability and consistency of system operations.&lt;/p&gt;&lt;h3&gt; 4) Automated State Control&lt;/h3&gt;&lt;p&gt; The fourth principle uses automation to keep our operating system in alignment with the desired state. Drift is the deviation of the runtime state of our system from the desired state. The system&amp;#x27;s blueprints and what is actually operating in the system don&amp;#x27;t match. Therefore, if the operating system drifts from what we have specified in Git, an operator will restore it by bringing it back to the intended condition.&lt;/p&gt;&lt;h2&gt; Benefits of GitOps&lt;/h2&gt;&lt;h3&gt; 1) Improves compliance and security:&lt;/h3&gt;&lt;p&gt; Since teams use a single platform for infrastructure management, a streamlined toolchain reduces attack surfaces. Teams can use the version control system to roll back to a desired state in the event of an assault. GitOps lessens outages and downtime as a result, allowing teams to continue working on projects in a secure environment.&lt;/p&gt;&lt;h3&gt; 2) Boosts productivity and cooperation:&lt;/h3&gt;&lt;p&gt; GitOps includes CI/CD pipelines, Git workflows, and infrastructure as code best practices for software development. These prerequisite tools, knowledge, and skill sets are already present in operations teams, thus adopting GitOps won&amp;#x27;t need a steep learning curve. GitOps workflows streamline procedures in order to improve visibility, establish a single source of truth, and have a small number of tools on hand.&lt;/p&gt;&lt;h3&gt; 3) Automation enhances developer efficiency and lowers costs:&lt;/h3&gt;&lt;p&gt; Productivity rises with CI/CD tooling and continuous deployment since teams can concentrate on development rather than laboriously manual processes thanks to automation. Since team members can use any language and tools they like before pushing updates to GitHub, GitOps workflows enhance the developer experience. Infrastructure automation increases output and decreases downtime while enabling better cloud resource management, which can also save costs.&lt;/p&gt;&lt;h3&gt; 4) Increases stability and reliability:&lt;/h3&gt;&lt;p&gt; Human mistake is decreased through infrastructure that is codified and repeatable. Code reviews and collaboration are made easier by merge requests, which also assist teams in finding and fixing issues before they are released to the public. Additionally, there is less risk because all infrastructure changes are tracked through merge requests and may be undone if an iteration is unsuccessful. By allowing rollbacks to a more stable state and providing distributed backup copies in the event of a significant outage, Git processes speed up recovery time. GitOps gives teams the freedom to iterate more quickly and release new features without worrying about creating an unstable environment.&lt;/p&gt;&lt;h3&gt; 5) Faster development and deployment:&lt;/h3&gt;&lt;p&gt; GitOps provides quicker and more frequent deployments, making it easier for teams to make a minimum viable change. Teams can ship many times per day and roll back changes if there is a problem by utilizing GitOps best practices. Team members can offer business and customer value more quickly thanks to high velocity deployments. Teams are more flexible and able to react to customer needs more quickly with continuous integration.&lt;/p&gt;&lt;h2&gt; Key Components of a GitOps workflow&lt;/h2&gt;&lt;p&gt; To summarize, the following are the four components we require to a GitOps workflow:&lt;/p&gt;&lt;ol&gt;&lt;li&gt; Git repository: The code and configuration of the application are verified there. &lt;/li&gt;&lt;li&gt; CD pipeline: It is responsible for building, testing, and deploying the application. &lt;/li&gt;&lt;li&gt; Application deployment tool: It is employed to manage the target environment&amp;#x27;s application resources. &lt;/li&gt;&lt;li&gt; Monitoring system: It keeps tabs on the performance of the application and gives the development team feedback. &lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Service Mesh: Consul]]></title><description><![CDATA[Explanation of Consul Connect]]></description><link>https://layer5.io/resources/service-mesh/service-mesh-consul</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/service-mesh-consul</guid><dc:creator><![CDATA[Deepesha Burse]]></dc:creator><pubDate>Fri, 05 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/ed21c2c53f2c64e86b016cfdfe7018ae/consul.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;h3&gt; What is a Service Mesh? &lt;/h3&gt;&lt;p&gt; A service mesh is a dedicated layer that provides secure service-to-service communication for on-prem, cloud, or multi-cloud infrastructure. Although service meshes are typically used with a microservice architectural pattern, they are useful in any situation involving complex networking. Their functionalities include traffic control, resiliency, observability and security. Traffic steering is used for content and it allows optimal usage of our resources. Service meshes provide control over chaotic situations (which usually arise in complex networks) along with proper identification and policies to enhance security. &lt;/p&gt;&lt;p&gt; Service meshes can be divided into the control plane and the data plane. The role of the control plane is to secure the mesh, facilitate service discovery, conduct frequent health checks, enforce policies and other operational concerns. Service discovery refers to a central registry of the services and their respective IP addresses. The application needs to be registered on the control plane for it to be able to share with other services how to communicate with it and helps to enforce rules on which service gets to communicate with which other services. &lt;/p&gt;&lt;p&gt; The data plane, on the other hand, handles the communication between services. The amount of knowledge that the services need to have about the network environment is limited by the fact that many service mesh solutions use a sidecar proxy to conduct data plane connections. &lt;/p&gt;&lt;img src=&quot;static/service-mesh-609aa147db2609960150f75fb05ab088.svg&quot; class=&quot;image-center&quot; alt=&quot;Service Mesh&quot;/&gt;&lt;h3&gt; What is Consul? &lt;/h3&gt;&lt;p&gt; Consul Service Mesh (also known as Consul Connect) provides service-to-service connection authorization and encryption using mutual Transport Layer Security (TLS). Consul is the control plane of the service mesh. Consul can be used with Virtual Machines (VMs), containers, or with container orchestration platforms such as Nomad and Kubernetes. Applications can use sidecar proxies to establish TLS connections for inbound and outbound connections or natively integrate with Connect by using Connect aware SDKs for optimal performance and security. &lt;/p&gt;&lt;p&gt; It is a multi-networking tool that provides a fully functional service mesh solution to address the networking and security issues associated with running cloud infrastructure and microservices. Consul offers a software technique for segmentation and routing. It also offers advantages such as handling failures, retries, and network observability. You can utilize any of these characteristics alone as required or combine them to create a full service mesh and achieve zero trust security. &lt;/p&gt;&lt;h3&gt; Architecture &lt;/h3&gt;&lt;p&gt; Consul is a distributed system built for a node cluster to operate on. A physical server, cloud instance, virtual machine, or container can all function as a Consul node. The collection of interconnected nodes that Consul runs on is known as a datacenter. Consul supports multiple datacenters and considers this as a common case. It is expected that there will be many clients and three to five servers in a datacenter. This creates a balance between performance and availability in the event of a breakdown because consensus slows down as more machines are added. The number of clients, however, is unlimited and can easily increase to thousands or tens of thousands. &lt;/p&gt;&lt;img src=&quot;static/datacenter-architecture-37152141459a591a624d6878e71817de.png&quot; class=&quot;image-center&quot; alt=&quot;Image of datacenter&quot;/&gt;&lt;p&gt; The Consul Agent is responsible for maintaining membership information, registering services, running checks, responding to queries, etc. It is required to run on every node that is a part of the Consul cluster. In some places, client agents may cache data from the servers to make it available locally for performance and reliability. They can either run in server mode or client mode. Client nodes make up for most of the cluster and are lightweight processes. They act as an interface between server nodes for most operations. They run on every node where services are running. &lt;/p&gt;&lt;p&gt; Along with core agent operations, a server node participates in the consensus quorum. The Raft protocol, which offers excellent consistency and availability in the event of failure, serves as the foundation for the quorum. Because they consume more resources than client nodes, server nodes should run on dedicated instances. &lt;/p&gt;&lt;img src=&quot;static/consul-agent-architecture-089f5381fe7bad46ed0bad733b454cc4.png&quot; class=&quot;image-center&quot; alt=&quot;Consul Agent&quot;/&gt;&lt;p&gt; A per-service proxy sidecar manages incoming and outgoing service connections by automatically wrapping and verifying TLS connections. Consul includes its own built-in L4 proxy and has first class support for Envoy. Other than this, we can choose to use any other proxy to plug in as well. The following diagram shows how proxies work: &lt;/p&gt;&lt;img src=&quot;static/service-proxy-architecture-a6b5364641023e65373a238beaf79ca0.png&quot; class=&quot;image-center&quot; alt=&quot;Side-car proxy&quot;/&gt;&lt;p&gt; The lifecycle of a Consul cluster:&lt;ol&gt;&lt;li&gt; An agent is started. &lt;/li&gt;&lt;li&gt; An agent joins the cluster. &lt;/li&gt;&lt;li&gt; Information of the agent is communicated throughout the cluster&lt;/li&gt;&lt;li&gt; Existing servers will begin replicating to the new node. &lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;&lt;h3&gt; Benefits and Compatibility of Consul Connect &lt;/h3&gt;&lt;p&gt; New methods of networking are necessary due to the development of cloud infrastructure and microservices designs. There are numerous tools and companies, all of which make different attempts to address the issue. The Consul service mesh solution offers a pure software approach with an emphasis on simplicity and wide compatibility and makes no assumptions about the underlying network. &lt;/p&gt;&lt;p&gt; Consul service mesh streamlines application deployment into a zero-trust network and makes service discovery easier in complex networking situations. &lt;/p&gt;&lt;p&gt; Features of Consul Service Mesh:&lt;br/&gt;&lt;ol&gt;&lt;li&gt; Service Discovery&lt;p&gt; Consul provides a service catalog, configurable service routing, health checks, automatic load balancing, and geo-failover across multiple instances of the same service. The capacity to control changes in the service landscape of your network becomes essential when new versions of a service are introduced and must coexist with existing instances of the same application, frequently running on different versions. The agent provides a simple service definition format to declare the availability of a service and to potentially associate it with a health check. &lt;/p&gt;&lt;/li&gt;&lt;li&gt; Zero-trust Security Model&lt;p&gt; Trust can be exploited and with the increasing number of services, there are higher chances of breach. The Consul service mesh control plane can be configured to enforce mutual TLS (mTLS), and will automatically generate and distribute the TLS certificates for every service in the mesh. The certificates are used for both service identity verification and communication encryption. &lt;/p&gt;&lt;/li&gt;&lt;li&gt; Simplify Application Security with Intentions&lt;p&gt; Communication between services is secure within the mesh once the service sidecar proxies have been set up. To designate which services are permitted to communicate with one another, you might want to build a more granular set of policies. Consul Intentions are used to limit which services can make requests or create connections and define access control for services through Connect. We can manage intentions via the UI, CLI, or API. The proxy or a natively integrated application enforces intentions on inbound connections or requests. &lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;&lt;p&gt; Compatibility of Consul Connect:&lt;br/&gt;&lt;ol&gt;&lt;li&gt; First-Class Kubernetes Support&lt;p&gt; By offering an official Helm chart for installing, configuring, and upgrading Consul on Kubernetes, Consul enables first-class Kubernetes support. The chart automates Kubernetes&amp;#x27;s Consul service mesh installation and configuration. &lt;/p&gt;&lt;/li&gt;&lt;li&gt; Platform Agnostic and Multi-Cluster Mesh&lt;p&gt; Consul works with all cloud providers and architectures. You can expand the scope of your Kubernetes clusters to include services that aren&amp;#x27;t run using Kubernetes by using the service catalog sync and auto-join features. In order to facilitate safe service-to-service communication between Nomad tasks and jobs, Consul additionally interfaces with HashiCorp Nomad. &lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Multi-Cluster Kubernetes Management with Meshery]]></title><description><![CDATA[Manage all of your Kubernetes clusters with the cloud native management plane, Meshery. Learn how Meshery makes connecting, discovering, and configuring multiple clusters a breeze.]]></description><link>https://layer5.io/blog/meshery/multi-cluster-kubernetes-management-with-meshery</link><guid isPermaLink="false">https://layer5.io/blog/meshery/multi-cluster-kubernetes-management-with-meshery</guid><dc:creator><![CDATA[Ashish Tiwari]]></dc:creator><pubDate>Thu, 28 Jul 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/322f708c880bf8749f760d3c3cad9a64/multi-cluster-kubernetes-management-with-meshery.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ZvKDg&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;From multi-mesh to now multi-cluster, &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt; is continuously expanding its capability to give developers, operators, and security engineers more control over their infrastructure. In this post, we&amp;#x27;ll take a look behind the scenes at how each component in Meshery&amp;#x27;s architecture plays a role in the management of many Kubernetes clusters.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;Philosophy behind Meshery&amp;#x27;s multi-cluster management approach&lt;/h2&gt;&lt;p&gt;While designing Meshery for the world of many service meshes, and many Kubernetes clusters, much care has been taken to ensure that Meshery is an &lt;a href=&quot;https://docs.meshery.io/extensibility&quot;&gt;extensible management platform&lt;/a&gt;, ready for handling new types of infrastructure and new use cases rapidly through its plugin model. Under the hood, &lt;a href=&quot;https://docs.meshery.io&quot;&gt;Meshery Server&lt;/a&gt; acts as a delegator of operations by figuring out which Meshery Adapter registered its capability against the given operation. The operation is then sent to that given component (like one of Meshery’s service mesh adapters,e.g. Istio adapter) via a gRPC call. &lt;img src=&quot;static/meshery-core-architecture-ec315a3f425831b199604a1b7fc15362.png&quot; alt=&quot;deploy modal&quot; class=&quot;image-right&quot;/&gt; When the operation involves a Kubernetes cluster(s), the kubeconfig(s) is sent as a parameter to the RPCs. It is then the job of the handling adapter to respect that and perform the operation across the passed clusters from kubeconfigs as needed. The operations not requiring a kubeconfig are managed through the same RPC, with the only difference being that the handling component would ignore the &lt;code&gt;kubeconfigs&lt;/code&gt; field altogether making the system work not just for Kubernetes, but for other cloud native use cases. This approach of reusing the same RPC for different types of requests is pretty common and sometimes debatable with the other approach of being strict with the RPCs. This is what makes Meshery completely pluggable and extensible.&lt;/p&gt;&lt;h2&gt;Using multi cluster with Meshery&lt;/h2&gt;&lt;p&gt;From a client&amp;#x27;s perspective, there are two uses of the multi context feature in general. While deploying a &lt;a href=&quot;/meshmap&quot;&gt;MeshMap&lt;/a&gt; design or performing any other operation on their cluster(s), selecting any number of Kubernetes contexts will allow them to uniformly and parallely perform the operation across the clusters. And while visualizing the state of their cluster(s), the same context switcher will allow them to filter across the clusters whose view they want to see.&lt;/p&gt;&lt;p&gt;All cluster specific operations are now applied over a number of clusters uniformly. So if you have 10 clusters to manage and 8 of those start with the exact same set of pods, deployments, service mesh, etc then &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt; can help you to apply these operations quickly and easily.&lt;/p&gt;&lt;p&gt;It is as simple as selecting the specific cluster(s) from the Kubernetes context switcher in the navbar, and then applying whatever operation you wanted to, whether that be deploying a sample app, a service mesh, or a &lt;a href=&quot;/meshmap&quot;&gt;MeshMap&lt;/a&gt; design.&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;static/context-switcher-85c34e8a44f40a03522e0b02b5689d68.png&quot; alt=&quot;context switcher&quot; class=&quot;image-center-shadow&quot;/&gt;&lt;/p&gt;&lt;p&gt;Just before applying the operation, you will be prompted with a confirmation modal which will provide the information about which cluster(s) that operation will be performed against. As the User interface improves, this same modal will also convey more useful information about the operation they are going to perform.&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;static/deploy-modal-19f06d7c3eb0bfa27b2b8a26c563f83d.png&quot; alt=&quot;deploy modal&quot; class=&quot;image-center-shadow&quot;/&gt;&lt;/p&gt;&lt;br/&gt;&lt;h3&gt;Using MeshMap visualizer&lt;/h3&gt;&lt;p&gt;You can switch between views of your cluster in visualizer mode while using &lt;a href=&quot;/meshmap&quot;&gt;MeshMap&lt;/a&gt;.&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;static/meshmap-cluster2-b545db5f3f28f44fb8154d6aab13d867.png&quot; alt=&quot;visualizer showing data of context1&quot; class=&quot;slides-right&quot;/&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;static/meshmap-cluster1-89fa20ad5fb543da3ded5afc8f57775f.png&quot; alt=&quot;visualizer showing data of context2&quot; class=&quot;slides-left&quot;/&gt;&lt;/p&gt;&lt;h3&gt;Managing Meshery on multiple clusters&lt;/h3&gt;&lt;p&gt;Users can perform cluster related operations from the settings page like adding more clusters, removing data from existing clusters and removing existing clusters.&lt;/p&gt;&lt;img src=&quot;static/settings-3b1ff1da147a0207419aafc162955ca1.png&quot; alt=&quot;Settings page&quot; class=&quot;slides-right&quot;/&gt;&lt;p&gt;Meshery also deploys Meshery operator across the cluster it’s about to manage. This operator manages the lifecycle of a Meshery broker and MeshSync. MeshSync pumps the blood into Meshery’s core, in other words, it is responsible for watching all different types of resources by establishing a watch stream over each of them. MeshSync then pumps that data into the NATS server, of which Meshery server itself is a client. From there, Meshery server gets all the relevant data related to activities in the cluster.&lt;/p&gt;&lt;p&gt;By default, &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt; wants to be as much aware about your infrastructure as possible to provide value so it deploys its operator across each detected cluster. But you can fine tune this configuration by going over each one of them from the table as shown.&lt;/p&gt;&lt;img src=&quot;static/cluster-mgmt-c9a54f4b6037ccb065b5e8993f49a895.png&quot; alt=&quot;Kubernetes multi-cluster management with Meshery&quot; class=&quot;image-center-shadow&quot;/&gt;&lt;p&gt;If you disconnect your cluster and do not want to persist the data from that cluster then you can perform a fine-grained deletion by deleting all MeshSync data (which are the Kubernetes objects) for that specific cluster.&lt;/p&gt;&lt;img src=&quot;static/flush-meshsync-417e908da2cf120f8936e90a43a07dbf.png&quot; alt=&quot;flushing MeshSync data&quot; class=&quot;image-center-shadow&quot;/&gt;&lt;h2&gt;Future of multi-cluster&lt;/h2&gt;&lt;p&gt;Meshery as an extension point to your infrastructure provides out-of-the-box value by adding components which can be Kubernetes specific, service mesh specific or custom components to add new functionality. We can now add multi-cluster specific components to provide more abstraction. This model can be used along with Meshery’s multi-mesh capabilities to give an overall multi-mesh multi-cluster experience to the user. For instance, your Istio service mesh spanning across multiple clusters can be abstracted and managed by Meshery using custom components such as VirtualGateway and VirtualDestinationRules. In this case, Meshery’s Istio adapter will handle the logic of converting a VirtualGateway into gateways across the clusters. This abstraction provides high value by powering the service mesh to span across the clusters while the Ops team can configure the mesh with minimal effort.&lt;/p&gt;&lt;p&gt;Just like the example above, many such Meshery extension points are in Meshery to add logic into and add useful functionality. And as more of such extension points are added, Meshery will continue to give more and more power to your cloud native infrastructure.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[How to deploy Meshery on AKS]]></title><description><![CDATA[How to deploy Meshery on Azure Kubernetes service(AKS).]]></description><link>https://layer5.io/blog/meshery/how-to-deploy-meshery-on-aks</link><guid isPermaLink="false">https://layer5.io/blog/meshery/how-to-deploy-meshery-on-aks</guid><dc:creator><![CDATA[Srinivas Karnati]]></dc:creator><pubDate>Thu, 21 Jul 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/4f9edd5fbd1229cce133102a7fa8d084/Meshery-on-AKS.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ZvKDg&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://meshery.io/&quot;&gt;Meshery&lt;/a&gt;&amp;#x27;s goal is to make the operation of cloud native infrastructure and the service mesh layer of cloud simplified. Originally created by Layer5, Meshery is an open source project with hundreds of contributors world-wide and is actively maintained by engineers from Red Hat, VMware, Intel, Layer5 and others.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;Setup and run Meshery on AKS&lt;/h2&gt;&lt;p&gt;The following instructions expects you to have an active Azure subscription, and Azure CLI installed on your system. &lt;/p&gt;&lt;h3&gt; Spin up the AKS Cluster&lt;/h3&gt;&lt;p&gt;Create the resource group (a logical group where all our resources will be deployed). The following command creates  a resource group named MesheryGroup in &lt;code&gt;southindia&lt;/code&gt; location. &lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;az group create --name MesheryGroup --location southindia&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Create AKS cluster using &lt;code&gt;az aks create&lt;/code&gt;. The following command creates aks cluster with a single node. &lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;az aks create --resource-group MesheryGroup --name MesheryAKS --node-count &lt;/span&gt;&lt;span class=&quot;token number&quot; style=&quot;color:rgb(247, 140, 108)&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; --generate-ssh-keys&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;After a few minutes, the command completes and returns a JSON formatted information about the cluster.&lt;/p&gt;&lt;p&gt;You can connect with your cluster by using &lt;code&gt;az aks get-credentials&lt;/code&gt; ,  which basically downloads credentials and configure the Kubernetes CLI. &lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;az aks get-credentials --resource-group MesheryGroup --name MesheryAKS&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Verify the connection to your cluster using the &lt;code&gt;kubectl get command&lt;/code&gt;. &lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$kubectl get nodes&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;h3&gt;Install Meshery into your AKS cluster&lt;/h3&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;helm repo add meshery https://meshery.io/charts/&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;helm install meshery meshery/meshery --namespace meshery --create-namespace&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Meshery server supports customizing authentication flow callback URL, which can be configured in the following way.&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;helm install meshery meshery/meshery --namespace meshery --set env.MESHERY_SERVER_CALLBACK_URL=https://custom-host --create-namespace&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Port forward to Meshery UI&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;export POD_NAME=$(kubectl get pods --namespace meshery -l &amp;quot;app.kubernetes.io/name=meshery,app.kubernetes.io/instance=meshery&amp;quot; -o jsonpath=&amp;quot;{.items[0].metadata.name}&amp;quot;)&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$ kubectl --namespace meshery port-forward $POD_NAME 9081:8080&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Meshery should now be running in your AKS cluster and the Meshery UI should be accessible at the specified endpoint you’ve exposed to. Navigate to the meshery service endpoint to log into Meshery.&lt;/p&gt;&lt;div&gt;&lt;img src=&quot;static/mesheryui-72711ded6ef62dddc649eba788fb6c88.png&quot; class=&quot;image-center&quot; alt=&quot;Meshery UI Dashboard&quot;/&gt;&lt;/div&gt;&lt;p&gt;From here, your Meshery deployment on AKS is ready to use. In order to login to Meshery, authenticate with your chosen provider from the list.&lt;/p&gt;&lt;p&gt;There are different ways to configure a Meshery on AKS. Join the &lt;a href=&quot;https://layer5.io/community&quot;&gt;community&lt;/a&gt; and share your deployment’s configuration on the &lt;a href=&quot;https://discuss.layer5.io/&quot;&gt; discussion forum &lt;/a&gt;today! &lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Managing Containers]]></title><link>https://layer5.io/resources/kubernetes/managing-containers</link><guid isPermaLink="false">https://layer5.io/resources/kubernetes/managing-containers</guid><pubDate>Wed, 06 Jul 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/70f4c7f444e8b3494ddc0fb955f86d40/docker.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Learn more about managing containers with our &lt;a class=&quot;blog&quot; href=&quot;https://github.com/layer5io/containers-101-workshop&quot;&gt;Containers 101 Workshop&lt;/a&gt;. Walk-through four hands-on exercises with Docker.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Container management refers to a set of practices that govern and maintain containerization software. Container management tools automate the creation, deployment, destruction and scaling of application or systems containers. Containerization is an approach to software development that isolates processes that share an OS kernel -- unlike virtual machines (VMs), which require their own -- and binds application libraries and dependencies into one deployable unit. This makes containers lightweight to run, as they require only the application configuration information and code from the host OS. This design also increases interoperability compared to VM hosting. Each container instance can scale independently with demand.&lt;/p&gt;&lt;p&gt;Modern Linux container technology was popularized by the Docker project, which started in 2013. Interest soon expanded beyond containerization itself, to the intricacies of how to effectively and efficiently deploy and manage containers.&lt;/p&gt;&lt;p&gt;In 2015, Google introduced the container orchestration platform Kubernetes, which was based on its internal data center management software called Borg. At its most basic level, open source Kubernetes automates the process of running, scheduling, scaling and managing a group of Linux containers. With more stable releases throughout 2017 and 2018, Kubernetes rapidly attracted industry adoption, and today it is the de facto container management technology.&lt;/p&gt;&lt;p&gt;IT teams use containers for cloud-native, distributed -- often microservices- based -- applications, and to package legacy applications for increased portability and efficient deployment. Containers have surged in popularity as IT organizations embrace DevOps, which emphasizes rapid application deployment. Organizations can containerize application code from development through test and deployment.&lt;/p&gt;&lt;h2&gt;Benefits of container management&lt;/h2&gt;&lt;p&gt;The chief benefit of container management is simplified management for clusters of container hosts. IT admins and developers can start, stop and restart containers, as well as release updates or check health status, among other actions. Container management includes orchestration and schedulers, security tools, storage, and virtual network management systems and monitoring.&lt;/p&gt;&lt;h3&gt;Wrangling container sprawl&lt;/h3&gt;&lt;p&gt;Organizations can set policies that ensure containers share a host -- or cannot share a host -- based on application design and resource requirements For example, IT admins should colocate containers that communicate heavily to avoid latency. Or, containers with large resource requirements might require an anti-affinity rule to avoid physical storage overload. Container instances can spin up to meet demand -- then shut down -- frequently. Containers also must communicate for distributed applications to work, without opening an attack surface to hackers.&lt;/p&gt;&lt;p&gt;A container management ecosystem automates orchestration, log management, monitoring, networking, load balancing, testing and secrets management, along with other processes. Automation enables IT organizations to manage large containerized environments that are too vast for a human operator to keep up with.&lt;/p&gt;&lt;h2&gt;Challenges of container management&lt;/h2&gt;&lt;p&gt;One drawback to container management is its complexity, particularly as it relates to open source container orchestration platforms such as Kubernetes and Apache Mesos. The installation and setup for container orchestration tools can be arduous and error prone. IT operations staff need container management skills and training. It is crucial, for example, to understand the relationships between clusters of host servers as well as how the container network corresponds to applications and dependencies.&lt;/p&gt;&lt;p&gt;Issues of persistence and storage present significant container management challenges. Containers are ephemeral -- designed to exist only when needed. Stateful application activities are difficult because any data produced within a container ceases to exist when the container spins down.&lt;/p&gt;&lt;p&gt;Container security is another concern. Container orchestrators have several components, including an API server and monitoring and management tools. These pieces make it a major attack vector for hackers. Container management system vulnerabilities mirror standard types of OS vulnerabilities, such as those related to access and authorization, images and intercontainer network traffic. Organizations should minimize risk with security best practices -- for example, identify trusted image sources and close network connections unless they&amp;#x27;re needed.&lt;/p&gt;&lt;h2&gt;Container management strategy&lt;/h2&gt;&lt;p&gt;Forward-thinking enterprise IT organizations and startups alike use containers and container management tools to quickly deploy and update applications. IT organizations must first implement the correct infrastructure setup for containers, with a solid grasp of the scope and scale of the containerization project in terms of business projections for growth and developers&amp;#x27; requirements. IT admins must also know how the existing infrastructure&amp;#x27;s pieces connect and communicate to preserve those relationships in a containerized environment. Containers can run on bare-metal servers, VMs or in the cloud -- or in a hybrid setup -- based on IT requirements.&lt;/p&gt;&lt;p&gt;In addition, the container management tool or platform should meet the project&amp;#x27;s needs for multi-tenancy; user and application isolation; authentication; resource requirements and constraints; logging, monitoring and alerts; backup management; license management; and other management tasks. IT organizations should understand their hosting commitment and future container plans, such as if the company will adopt multiple cloud platforms or a microservices architecture.&lt;/p&gt;&lt;h2&gt;Kubernetes implementation considerations&lt;/h2&gt;&lt;p&gt;As described above, containers are arranged into pods in Kubernetes, which run on clusters of nodes; pods, nodes and clusters are controlled by a master. One pod can include one or multiple containers. IT admins should carefully consider the relationships between pods, nodes and clusters when they set up Kubernetes.&lt;/p&gt;&lt;p&gt;Organizations should plan their container deployment based on how many pieces of the application can scale under load -- this depends on the application, not the deployment method. Additionally, capacity planning is vital for balanced pod-to-node mapping, and IT admins should ensure high availability with redundancy with master node components.&lt;/p&gt;&lt;p&gt;IT organizations can address container security concerns by applying some general IT security best practices to containerization. For example, create multiple security layers throughout the environment, scan all container images for vulnerabilities, enforce signed certificates and run the most up-to-date version of any container or application image. Containers introduce the benefits of an immutable infrastructure methodology as well; the regular disposal and redeployment of containers, with their associated components and dependencies, improves overall system availability and security. Additionally, Kubernetes multi-tenancy promises greater resource isolation, but recently revealed security vulnerabilities make multicluster management preferred for now.&lt;/p&gt;&lt;p&gt;Networking is another significant factor. Kubernetes networking occurs within pods, between pods and in user-to-containerized resource connections. Kubernetes enables pods and nodes to communicate without address translation, allocating subnets as necessary. Lastly, IT admins working with Kubernetes should prepare to troubleshoot common container performance problems, including those caused by unavailable nodes and noisy neighbors, in an implementation.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Kubernetes Architecture 101]]></title><link>https://layer5.io/resources/kubernetes/kubernetes-architecture-101</link><guid isPermaLink="false">https://layer5.io/resources/kubernetes/kubernetes-architecture-101</guid><pubDate>Tue, 05 Jul 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/9287b4a708bb510f64057ea305498b77/kubernetes.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;p&gt;The way Kubernetes is architected is what makes it powerful. Kubernetes has a basic client and server architecture, but it goes way beyond that. Kubernetes has the ability to do rolling updates, it also adapts to additional workloads by auto scaling nodes if it needs to and it can also self-heal in the case of a pod meltdown. These innate abilities provide developers and operations teams with a huge advantage in that your applications will have little to no down time. In this section we provide a brief overview of the master and its worker nodes with a high level overview of how Kubernetes manages workloads.&lt;/p&gt;&lt;div class=&quot;right&quot;&gt;&lt;img src=&quot;static/kubernetes-highlevel-architecture-5759d8cb4ac0991f91ef736d48e531fc.png&quot; alt=&quot;Simple Kubernetes Architecture Diagram&quot;/&gt;&lt;i&gt;Simple Kubernetes Architecture Diagram&lt;/i&gt;&lt;/div&gt;&lt;h1&gt;Kubernetes Components&lt;/h1&gt;&lt;p&gt;Let&amp;#x27;s dive into each of the Kubernetes components, starting with the Master node.&lt;/p&gt;&lt;h2&gt;Kubernetes Master&lt;/h2&gt;&lt;p&gt;The Kubernetes master is the primary control unit for the cluster. The master is responsible for managing and scheduling the workloads in addition to the networking and communications across the entire cluster. The master node is responsible for the management of Kubernetes cluster. This is the entry point of all administrative tasks. The master node is the one taking care of orchestrating the worker nodes, where the actual services are running.&lt;/p&gt;&lt;p&gt;These are the components that run on the master:&lt;/p&gt;&lt;h3&gt;Etcd Storage&lt;/h3&gt;&lt;p&gt;Etcd is an open-source key-value data store that can be accessed by all nodes in the cluster. It stores configuration data of the cluster’s state. etcd is a simple, distributed, consistent key-value store. It’s mainly used for shared configuration and service discovery.&lt;/p&gt;&lt;p&gt;It provides a REST API for CRUD operations as well as an interface to register watchers on specific nodes, which enables a reliable way to notify the rest of the cluster about configuration changes.&lt;/p&gt;&lt;p&gt;An example of data stored by Kubernetes in etcd is jobs being scheduled, created and deployed, pod/service details and state, namespaces and replication information, etc.&lt;/p&gt;&lt;h3&gt;Kube-API-Server&lt;/h3&gt;&lt;p&gt;Kube-API-Server manages requests from the worker nodes, and it receives REST requests for modifications, and serves as a front-end to control cluster. The API server is the entry points for all the REST commands used to control the cluster. It processes the REST requests, validates them, and executes the bound business logic. The result state has to be persisted somewhere, and that brings us to the next component of the master node.&lt;/p&gt;&lt;h3&gt;Kube-scheduler&lt;/h3&gt;&lt;p&gt;Kube-scheduler schedules the pods on nodes based on resource utilization and also decides where services are deployed. The deployment of configured pods and services onto the nodes happens thanks to the scheduler component. The scheduler has the information regarding resources available on the members of the cluster, as well as the ones required for the configured service to run and hence is able to decide where to deploy a specific service.&lt;/p&gt;&lt;h3&gt;Kube-controller-manager&lt;/h3&gt;&lt;p&gt;Kube-controller-manager runs a number of distinct controller processes in the background to regulate the shared state of the cluster and perform routine tasks. When there is a change to a service, the controller recognizes the change and initiates an update to bring the cluster up to the desired state. Optionally you can run different kinds of controllers inside the master node. controller-manager is a daemon embedding those.&lt;/p&gt;&lt;p&gt;A controller uses apiserver to watch the shared state of the cluster and makes corrective changes to the current state to change it to the desired one.
An example of such a controller is the Replication controller, which takes care of the number of pods in the system. The replication factor is configured by the user, and it&amp;#x27;s the controller’s responsibility to recreate a failed pod or remove an extra-scheduled one. Other examples of controllers are endpoints controller, namespace controller, and serviceaccounts controller, but we will not dive into details here.&lt;/p&gt;&lt;h2&gt;Worker Nodes&lt;/h2&gt;&lt;p&gt;These nodes run the workloads according the schedule provided by the master. The interaction between the master and worker nodes are what’s known as the control plane. The pods are run here, so the worker node contains all the necessary services to manage the networking between the containers, communicate with the master node, and assign resources to the containers scheduled.&lt;/p&gt;&lt;h3&gt;Kubelet&lt;/h3&gt;&lt;p&gt;Kubelet ensures that all containers in the node are running and are in a healthy state.  If a node fails, a replication controller observes this change and launches pods on another healthy pod. Integrated into the kubelet binary is ‘cAdvisor` that auto-discovers all containers and collects CPU, memory, file system, and network usage statistics and also provides machine usage stats by analyzing the ‘root’ container. &lt;/p&gt;&lt;p&gt;Kubelet gets the configuration of a pod from the apiserver and ensures that the described containers are up and running. This is the worker service that’s responsible for communicating with the master node. It also communicates with etcd, to get information about services and write the details about newly created ones.&lt;/p&gt;&lt;h3&gt;Kube Proxy&lt;/h3&gt;&lt;p&gt;Kube Proxy acts as a network proxy and a load balancer for a service on a single worker node. . It takes care of the network routing for TCP and UDP packets. It forwards the request to the correct pods across isolated networks in a cluster. &lt;/p&gt;&lt;h3&gt;Pods&lt;/h3&gt;&lt;p&gt;A pod is the basic building block on Kubernetes. It represents the workloads that get deployed. Pods are generally collections of related containers, but a pod may also only have one container. A pod shares network/storage and also a specification for how to run the containers.&lt;/p&gt;&lt;h3&gt;Containers&lt;/h3&gt;&lt;p&gt;Containers are the lowest level of microservice. These are placed inside of the pods and need external IP addresses to view any outside processes. Docker is not the only supported container runtime, but is by far, the most popular. Docker runs on each of the worker nodes, and runs the configured pods. It takes care of downloading the images and starting the containers.&lt;/p&gt;&lt;h3&gt;kubectl&lt;/h3&gt;&lt;p&gt;Kubectl is a command line tool to communicate with the API service and send commands to the master node. kubectl must be configured to communicate with your cluster. If you have multiple clusters, you might try using kubectx, which makes switching between contexts easy.&lt;/p&gt;&lt;h4&gt;Managing objects with kubectl&lt;/h4&gt;&lt;p&gt;You can divide a Kubernetes cluster into multiple environments by using namespaces (e.g., Dev1, Dev2, QA1, QA2, etc.), and each environment can be managed by a different user. One of the inconveniences of writing kubectl commands is that every time you write a command, you need the --namespace option at the end. People often forget this and end up creating objects (pods, services, deployments) in the wrong namespace. &lt;/p&gt;&lt;p&gt;With this trick, you can set the namespace preference before running kubectl commands. Run the following command before executing the kubectl commands, and it will save the namespace for all subsequent kubectl commands for your current context:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;kubectl config set-context $(kubectl config current-context) --namespace=mynamespace&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[What is Multi-Cluster Kubernetes?]]></title><link>https://layer5.io/resources/kubernetes/what-is-multi-cluster-kubernetes</link><guid isPermaLink="false">https://layer5.io/resources/kubernetes/what-is-multi-cluster-kubernetes</guid><pubDate>Tue, 05 Jul 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/9287b4a708bb510f64057ea305498b77/kubernetes.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;Developers who work in fast-paced environments face the risk of infrastructure sprawl in their VMs or servers. Even with the rise in containerized deployments on Kubernetes and other platforms, admins still must determine how to efficiently manage hundreds and thousands of clusters for various projects.&lt;p&gt;Common concerns for an organization’s project deployments include how to run multiple workloads and whether a cluster is large enough to handle the work.&lt;/p&gt;&lt;p&gt;A Kubernetes multi-cluster setup can solve these problems. Multi-cluster architecture is a strategy for spinning up several clusters to achieve better isolation, availability, and scalability. In this type of implementation, an application’s infrastructure is distributed and maintained across multiple clusters. Because this strategy can also make cluster management more difficult, it needs to be handled properly.&lt;/p&gt;&lt;h2&gt;What Is a Kubernetes Multi-Cluster Setup?&lt;/h2&gt;&lt;p&gt;Kubernetes works with clusters to efficiently run and manage workloads.&lt;/p&gt;&lt;p&gt;In Kubernetes multi-cluster orchestration, platforms such as managed services help you to run workloads across multiple clusters and environments. The multiple clusters can be configured within a single physical host, within multiple hosts in the same data center, or even in a single cloud provider across different regions. This allows you to provision your workloads in several clusters, rather than just one.&lt;/p&gt;&lt;p&gt;This type of deployment enables more scalability, availability, and isolation for your workloads and environments. It also enables you to better coordinate the planning, delivery, and management of these environments.&lt;/p&gt;&lt;p&gt;A key feature of multi-cluster Kubernetes architecture is that each cluster is highly independent, managing its internal state for maximum resource provisioning and service configuration.&lt;/p&gt;&lt;h2&gt;Why Use a Kubernetes Multi-Cluster Setup?&lt;/h2&gt;&lt;p&gt;There are multiple use cases for a multi-cluster deployment. You can use it to deploy workloads spanning multiple regions for increased availability, eliminate cloud blast radius, prevent compliance issues, and enforce security around your clusters and tenants.&lt;/p&gt;&lt;p&gt;As your environment grows, so do the potential issues you need to solve in order to align your cluster maintenance with your business needs. Using a Kubernetes multi-cluster setup can help with the following concerns.&lt;/p&gt;&lt;h2&gt;Cluster Discovery and Tenant Isolation&lt;/h2&gt;&lt;p&gt;It is common for projects to exist in dev, staging, and production environments. To achieve this kind of isolation, you require multiple Kubernetes environments.&lt;/p&gt;&lt;p&gt;Conventionally, using namespaces would be enough for discovery and isolation in a single cluster, but Kubernetes isn’t a direct multitenant system. Namespaces are also not great for isolation since any compromise in the namespace means that your cluster is also compromised. Additionally, badly configured applications in a namespace can consume more resources than expected, which impacts other applications in the cluster.&lt;/p&gt;&lt;p&gt;Kubernetes multi-cluster environments enable you to isolate users and projects by cluster, simplifying the process.&lt;/p&gt;&lt;h2&gt;Failover&lt;/h2&gt;&lt;p&gt;Architecting multi-cluster workloads minimizes the downtime issues common within a single cluster, because you can freely transfer the workloads to other running clusters.&lt;/p&gt;&lt;h1&gt;Multi-Cluster, Multitenancy, or a Mix?&lt;/h1&gt;&lt;p&gt;Kubernetes is a complex, high-level platform that offers multiple options for your deployments: single server, multitenant, or multi-cluster.&lt;/p&gt;&lt;p&gt;Multitenancy means a cluster is shared among several workloads, or tenants. Multiple users share the same cluster resources and control plane. Multitenant clusters require fair allocation of resources to the tenants as well as isolation of tenants from each other, in order to minimize the effects of a faulty tenant on other tenants and the overall cluster.&lt;/p&gt;&lt;p&gt;A multi-cluster setup, on the other hand, involves several clusters deployed across one or many data centers. This type of deployment can be used to separate development and production. It improves availability and enhances security around workloads.&lt;/p&gt;&lt;p&gt;The best choice for your organization depends on factors that include the technical expertise of your team, your infrastructure availability, and your budget. Many organizations separate their critical production services from non-critical services by placing them in separate tenants across tiers, teams, locations, or infrastructure providers. Projects that are time- and resource-dependent (where resources are spun up and down on the go) are, however, suitable for multi-cluster architecture.&lt;/p&gt;&lt;h1&gt;When to Use a Multi-Cluster Setup&lt;/h1&gt;&lt;p&gt;To decide whether your projects would function best in a multi-cluster deployment, you first need to define your goals.&lt;/p&gt;&lt;p&gt;You should know the challenges you are trying to solve and how transitioning to a multi-cluster setup would help your organization. Projects that are performance-dependent with workloads that are sensitive to factors like latency can take advantage of the high availability and isolation available in multi-cluster setups. In other words, you can run workloads with intensive computations that don’t need to share resources.&lt;/p&gt;&lt;p&gt;You’ll need to collect workload data and other feedback from your various teams before making a decision. You should assess your teams’ expertise: are they well-versed in provisioning single clusters, even before transitioning to multi-clusters? You’ll also need to evaluate your business model and how such an infrastructure transition could affect your users or customers.&lt;/p&gt;&lt;p&gt;The following are some of the advantages of transitioning to a Kubernetes multi-cluster setup.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Tenant Isolation&lt;/li&gt;You might want to establish order while accommodating your development teams. The multi-cluster architecture allows workload isolation. For example, you could spin up separate clusters for staging and production.&lt;p&gt;With multiple clusters, any tenant configuration changes affect only that specific cluster. This way, cluster admins can easily identify issues, run new feature experiments, and carry out workload shifts without troubling other tenants and clusters.&lt;/p&gt;&lt;li&gt;No  Single Point of Failure&lt;/li&gt;Running a single cluster can expose your project to a single point of failure, in which one malfunctioning component can bring down an entire system. Using a multi-cluster environment enables you to shift your workloads between clusters so that your projects continue to function if one cluster is down or even disappears entirely.&lt;li&gt;No Vendor Lock-In&lt;/li&gt;There are multiple third-party cloud vendors available with varying resource offerings. Because of evolving resource pricing and models, organizations change their usage models over time as well. A Kubernetes multi-cluster setup ensures your workloads are cloud-agnostic so that you can safely use multiple vendors or move workloads from one cloud to another.&lt;/ul&gt;&lt;p&gt;Kubernetes provisions clusters that run and manage our workloads. Depending on the needs of an organization, Kubernetes deployments can be replicated to have the same workloads accessible across multiple nodes and environments. This concept is called Kubernetes multi-cluster orchestration. It’s simply provisioning your workloads in several Kubernetes clusters (going beyond a single cluster). &lt;/p&gt;&lt;p&gt;A Kubernetes multi-cluster defines deployment strategies to introduce scalability, availability, and isolation for your workloads and environments. A Kubernetes multi-cluster is fully embraced when an organization coordinates the planning, delivery, and management of several Kubernetes environments using appropriate tools and processes.&lt;/p&gt;&lt;h2&gt;Why Do You Need a Kubernetes Multi-Cluster?&lt;/h2&gt;&lt;p&gt;In simple deployment cases, Kubernetes can spin workloads in a single cluster. However, some cases need advanced deployment models, and for such scenarios, a multi-cluster architecture is suitable and can improve the performance of your workloads.&lt;/p&gt;&lt;p&gt;Simply put, a development team may need a Kubernetes multi-cluster to handle workloads spanning regions, eliminate a cloud blast radius, manage compliance requirements, solve multi-tenancy conflicts, and enforce security around clusters and tenants.&lt;/p&gt;&lt;h3&gt;Cluster Upgrades and Security Management&lt;/h3&gt;&lt;p&gt;Teams that rely heavily on Kubernetes for deployments need to plan for regular upgrades and patches on their environments for comprehensive security fixes.&lt;/p&gt;&lt;p&gt;Running cluster upgrades without due care or proper tools can break more things, and more so when dependent resources are overloaded. Tools like kOPs and Cluster APIs can therefore be used to apply upgrades to your running clusters.&lt;/p&gt;&lt;p&gt;The tools that you install to run your clusters depend entirely on the workloads that your clusters support. How you upgrade a cluster and its tools also depends on how you initially deployed and ran the Kubernetes cluster, that is, whether you’re using a hosted Kubernetes provider or some other means for deployment. Most hosted providers support and handle automatic upgrades, which relieves developers from manual upgrades and patching.&lt;/p&gt;&lt;p&gt;Upgrading a cluster and its toolset follows the approach of upgrading the control plane first, then the nodes in a cluster, followed by upgrading clients such as &lt;code&gt;kubectl&lt;/code&gt;.&lt;/p&gt;&lt;h3&gt;Managing Kubernetes Multi-Cluster Complexity&lt;/h3&gt;&lt;p&gt;The complexity of management tasks across multiple Kubernetes clusters greatly increases your the number of clusters increase. You need higher-level view and control as you manage workloads across clusters; need to be able to simply switch between clusters; you need a management plane. &lt;/p&gt;&lt;a class=&quot;blog&quot; href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt; is the open source, cloud native management plane that enables the adoption, operation, and management of Kubernetes, any service mesh, and their workloads.&lt;p&gt;MeshSync, a custom controller managed by Meshery Operator, uniquely contains cluster-wide details of all objects across any number of managed clusters separated by Kubernetes Cluster ID. &lt;/p&gt;&lt;h3&gt;Deprovisioning Clusters That Are No Longer Needed&lt;/h3&gt;&lt;p&gt;When you deprovision a cluster, its running resources are also deleted. The control plane resources, the node instances, pods, and stored data are all deleted.&lt;/p&gt;&lt;p&gt;Different hosted Kubernetes providers have varying ways of deleting Kubernetes clusters. For instance, GKE supports deletion of clusters from the Google Cloud CLI and Cloud Console. Other tools for spinning Kubernetes clusters such as kOps and Amazon EKS also support the deletion from their CLIs and consoles.&lt;/p&gt;&lt;p&gt;Suppose you have provisioned your clusters with the Google Kubernetes Engine; you can run the following command in the gcloud CLI to deprovision your clusters that are no longer needed:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;gcloud container clusters delete CLUSTER_NAME&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;At this point, you’ve seen the operations around managing a cluster lifecycle, that is, creation, deletion, and upgrading of clusters.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Teams want working with clusters to be as easy as possible. This ease in operating clusters can be ensured by managing the cluster lifecycle. In this article, you learned what’s involved in managing a cluster lifecycle. You’ve seen how clusters are created at scale using various tools. You’ve also seen what cluster upgrades and security patch management involve while trying to maintain the health of your clusters.&lt;/p&gt;&lt;p&gt;The complexity of Kubernetes environments does present challenges, but setting clear goals and objectives for deploying your clusters can help you overcome any obstacles as your organization makes the transition.&lt;/p&gt;&lt;p&gt;Finally, multi-cluster deployments are a good choice for organizations that are building highly distributed systems, with geographic and regulatory control in check to help scale workloads beyond the limits of single clusters. Multi-cluster deployment and management is useful for minimizing exposure of production services, preventing access to sensitive data in environments like development and testing. Organizations are now opting to deploy their more critical workloads on separate multiple clusters from their less critical ones.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[TechStrong TV Interview]]></title><link>https://layer5.io/resources/interview/techstrong-tv-interview</link><guid isPermaLink="false">https://layer5.io/resources/interview/techstrong-tv-interview</guid><pubDate>Sat, 25 Jun 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/12cf27fc20e91ecb3f581a9f5b187743/techstrong.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;p&gt;TechStrong TV hosts a variety of live conversations and panel discussions with world’s leading technology experts and leaders at global tech events and user conferences. In this episode of TechStrong TV, straight out of &lt;a href=&quot;/community/events/open-source-summit-north-america-2022&quot;&gt;Open Source Summit NA 2022&lt;/a&gt; , catch guest &lt;a href=&quot;https://layer5.io/community/members/lee-calcote&quot;&gt;Lee Calcote&lt;/a&gt; from Layer5 and host Alan Shimel discuss the power of &lt;a href=&quot;/projects&quot;&gt;Layer5 projects&lt;/a&gt; in managing service meshes, Kubernetes and the rest of your cloud native infrastucture. They also dive into some of the other network-centric CNCF projects like CoreDNS and gRPC. Tune in now!&lt;/p&gt;&lt;a href=&quot;https://digitalanarchist.com/videos/open-source-summit-na-2022/lee-calcote-layer5&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 fJwHWC appion__btn btn-center&quot;&gt;&lt;h3&gt;Check out the TechStrong TV Interview with Layer5!&lt;/h3&gt; &lt;/button&gt;&lt;/a&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Istio Virtual Service]]></title><link>https://layer5.io/resources/service-mesh/istio-virtual-service</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/istio-virtual-service</guid><pubDate>Thu, 16 Jun 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/731763d720780a49c2ffdfede8c28f4b/istio.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;p&gt;Istio Virtual Service defines a set of traffic routing rules to apply when host is addressed. Each routing rule defines standards for the traffic of a specific protocol. If the traffic is matched, then it is sent to a named destination service defined in the registry.&lt;/p&gt;&lt;p&gt;The source of traffic can also be matched within a routing rule that allows routing to be customized for every specific client context.&lt;/p&gt;&lt;div class=&quot;fact-left&quot;&gt;&lt;p&gt;The below example on Kubernetes routes all HTTP traffic by default to pods of the reviews service with the label “version: v1”. Additionally, HTTP requests with path starting with /wpcatalog/ or /consumercatalog/ will be rewritten to /newcatalog and sent to the pods with label “version: v2”.&lt;/p&gt;&lt;/div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;apiVersion: networking.istio.io/v1alpha3&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;kind: VirtualService&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;metadata:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  name: reviews-route&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;spec:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  hosts:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  - reviews.prod.svc.cluster.local&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  http:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  - name: &amp;quot;reviews-v2-routes&amp;quot;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    match:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    - uri:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;        prefix: &amp;quot;/wpcatalog&amp;quot;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    - uri:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;        prefix: &amp;quot;/consumercatalog&amp;quot;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    rewrite:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      uri: &amp;quot;/newcatalog&amp;quot;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    route:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    - destination:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;19&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;        host: reviews.prod.svc.cluster.local&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;        subset: v2&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  - name: &amp;quot;reviews-v1-route&amp;quot;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    route:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    - destination:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;        host: reviews.prod.svc.cluster.local&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;        subset: v1&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;h2&gt;Virtual Service Configuration Affecting Traffic Routing &lt;/h2&gt;&lt;p&gt;A single Virtual Service can be used to describe all the traffic properties of the hosts, including those for multiple HTTP and TCP ports.&lt;/p&gt;&lt;div&gt;&lt;h3&gt;Hosts&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;The application traffic created by hosts, clients, servers, and applications that use the network as a transport is contained in the physical network data plane (also known as the forwarding plane). As a result, data plane traffic should never have source or destination IP addresses that are assigned to network elements like routers and switches; instead, it should be originated from and delivered to end devices like PCs and servers. To forward data plane traffic as swiftly as possible, routers and switches use hardware chips called application-specific integrated circuits (ASICs). A forwarding information base is referenced by the physical networking data plane (FIB).&lt;/li&gt;&lt;li&gt;The destination hosts to which traffic is being sent it could be a DNS name with wildcard prefix or an IP address depending on the platform.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;h3&gt;Gateways&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;The names of gateways and sidecars that should apply all these routes. Gateways in other namespaces may be referred to by &lt;code&gt; gateway namespace&amp;gt;/gateway name &lt;/code&gt;; specifying a gateway with no namespace qualifier is the same as specifying the VirtualService’s namespace.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;h3&gt;HTTP&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;An ordered list of route rules for HTTP traffic. The HTTP routes will be applied to the platform service ports named &lt;code&gt;‘http-’/‘http2-’/‘grpc-*’, gateway ports with protocol HTTP/HTTP2/GRPC/ TLS-terminated-HTTPS &lt;/code&gt; and service entry ports using HTTP/HTTP2/GRPC protocols.&lt;/li&gt;&lt;li&gt;The first rule is matching an incoming request which is used.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;h3&gt;TCP&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;An ordered list of all the routing rules for opaque TCP traffic. TCP routes will be applied to any of the port which is not a HTTP or TLS port.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;h3&gt;ExportTo&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Exporting a virtual service allows it to be used by the sidecars and the gateways defined in other namespaces.&lt;/li&gt;&lt;li&gt;If no namespaces are specified then the virtual service is exported to all namespaces by default.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;h2&gt;Destination&lt;/h2&gt;&lt;p&gt;A destination indicates that the network addressable service to which the request/connection will be sent. A DestinationRule defines policies that apply to traffic intended for a service after routing has occurred.&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;apiVersion: networking.istio.io/v1alpha3&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;kind: DestinationRule&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;metadata:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  name: reviews-destination&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;spec:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  host: reviews.prod.svc.cluster.local&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  subsets:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  - name: v1&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    labels:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      version: v1&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  - name: v2&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    labels:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      version: v2&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;div class=&quot;fact-left&quot;&gt;&lt;p&gt;A version of the route destination is identified with a reference to a named service subset which should be declared in a corresponding DestinationRule.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Validating Meshery CLI Functionality]]></title><description><![CDATA[Guide for End to End manual testing Meshery CLI (mesheryctl)]]></description><link>https://layer5.io/blog/meshery/validating-meshery-cli-functionality</link><guid isPermaLink="false">https://layer5.io/blog/meshery/validating-meshery-cli-functionality</guid><dc:creator><![CDATA[Piyush Singariya]]></dc:creator><pubDate>Fri, 10 Jun 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/263b448473ae33e3174e15410c694e8c/thumbnail.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ZvKDg&quot;&gt;&lt;p&gt;Hola folks, &lt;/p&gt;&lt;p&gt;As a contributor, each of us is always striving hard in the ocean to open more and more pull-requests, but being a contributor just doesn&amp;#x27;t mean only raising PRs, it also means reviewing other PRs, pointing out mistakes, helping others in improving the code-quality/code-reusability/code-readability, helping in finding missing edge-cases that haven&amp;#x27;t been tackled yet, giving your opinions, writing LGTM, CITY helps nothing but just improving the confidence and engagement of the PR author.&lt;/p&gt;&lt;p&gt;So put on your &lt;strong&gt;Quality Tester&lt;/strong&gt; hats because here I&amp;#x27;ll talk about how to test the PRs with the label &lt;code&gt;component/mesheryctl&lt;/code&gt; i.e. pull-requests related to &lt;code&gt;mesheryctl&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Okay before we start, I&amp;#x27;ll like to tell you about &lt;a href=&quot;https://github.com/cli/cli&quot;&gt;GitHub CLI&lt;/a&gt;, it helps you checkout PRs very easily in your local system.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;The very first step is to review the PR, suggest changes if you think of any, ask queries, help the author to improve the code quality/readability/reusability, ask questions because asking helps you learn asking more better questions next time.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;PR authors either attach a video showcasing expected behavior or add written instructions about their fix under &lt;strong&gt;User Acceptance Behavior&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Now it&amp;#x27;s the time to checkout PR in your local system, we can check out any PR like this&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;gh &lt;/span&gt;&lt;span class=&quot;token function&quot; style=&quot;color:rgb(130, 170, 255)&quot;&gt;pr&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; checkout https://github.com/meshery/meshery/pull/4823&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You can check if you&amp;#x27;re into the same branch as the PR author with &lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token function&quot; style=&quot;color:rgb(130, 170, 255)&quot;&gt;git&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; branch&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Well, if we&amp;#x27;re testing a PR related to mesheryctl, we need to build the binary from the same branch. change your directory to &lt;code&gt;mesheryctl&lt;/code&gt; folder and run&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token function&quot; style=&quot;color:rgb(130, 170, 255)&quot;&gt;make&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;This will create a mesheryctl binary according to your OS in the same directory&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Now it&amp;#x27;s time to test out this newly built binary according to what&amp;#x27;s been tackled in the PR and related issues. For e.g. &lt;code&gt;system start&lt;/code&gt; has some new functionality, make sure you followed the pull-request/linked-issue instruction for env setup, as sometimes fix/features are tackling an issue with a specific type of environment.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;./mesheryctl system start&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;the &lt;code&gt;./&lt;/code&gt; helps us in using the newly built cli-binary present in the current directory which we built in 5th step&lt;/p&gt;&lt;ol start=&quot;7&quot;&gt;&lt;li&gt;make sure we have a similar experience as mentioned in the Video or the instructions added to the PR. but the wait is it okay to give green flags to the PR? not yet tbh. We as a tester should turn a little evil and think of the relevant situations/environments which might not have been tackled but should be(basically we&amp;#x27;re trying to break the new feature/fix)&lt;/li&gt;&lt;li&gt;After spending a good amount of time testing the new behaviors, old standard behaviors, new test cases, few edge cases. We can provide new insights to the PR author about the behavior in your system, depending on our experience we can ask the PR author to address our new queries, or we can appreciate the work, or give green flags to the PR.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Wow, that was a ton of work there. well being a Tester is tough but very important before we merge pull requests. Every PR should be marked green with end-to-end testing before merging, we as a project are using GH Workflows to perform standard golang-testing but manual end-to-end testing completely removes margins of error.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Evolution of the Meshery CLI Command Reference]]></title><description><![CDATA[Autogeneration of Meshery CLI command reference]]></description><link>https://layer5.io/blog/meshery/evolution-of-the-meshery-cli-command-reference</link><guid isPermaLink="false">https://layer5.io/blog/meshery/evolution-of-the-meshery-cli-command-reference</guid><dc:creator><![CDATA[Aadhitya Amarendiran]]></dc:creator><pubDate>Thu, 09 Jun 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/0ec8439c9cc7b3a2b248d2fc9b3ce62c/mesheryctl.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ZvKDg&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Documentation plays a major role in any project. Even if the project is small or too big, the creator or the team behind the project needs to curate the documentation very well such that it&amp;#x27;ll be useful for new end users to refer and learn to use the project, troubleshoot the problems occurred and lot more. Thus, we, Layer5 have curated the documentation for Meshery to meet such purposes. Not to mention, &lt;code&gt;mesheryctl&lt;/code&gt;, the CLI client of Meshery needs a curated documentation as well. This blog describes about the evolution of &lt;code&gt;mesheryctl&lt;/code&gt; command reference page. &lt;/p&gt;&lt;/div&gt;&lt;h3&gt;Initial Command Reference Design&lt;/h3&gt;&lt;p&gt;The initial design of &lt;code&gt;mesheryctl&lt;/code&gt; command reference page is all made using pure markdown and the functionality is handled using Jekyll, the main framework used for Meshery Docs. This handled great at initial stage but had many limitations, such as:&lt;ul&gt;&lt;li&gt;Updation of YAML for data is often required&lt;/li&gt;&lt;li&gt;Design was obselete at initial stage&lt;/li&gt;&lt;li&gt;No separate pages for each command and subcommand&lt;/li&gt;&lt;/ul&gt;Thus, the idea for redesigning the &lt;code&gt;mesheryctl&lt;/code&gt; reference page was desperately needed.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://docs.meshery.io&quot; alt=&quot;Meshery Documentation&quot; target=&quot;_parent&quot;&gt;&lt;img src=&quot;static/initial-design-5812f801a3ab38a2d0ac62b76983f6c4.png&quot; class=&quot;image-center-shadow&quot; alt=&quot;Initial design of mesheryctl command reference&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;Updated Command Reference Design&lt;/h3&gt;&lt;p&gt;To tackle the shortcomings of the previous design, I was tasked to redesign the &lt;code&gt;mesheryctl&lt;/code&gt; command reference page entirely. This was a big task at first glance to me, as I was a new contributor back then. Eventually after manipulating the reference section with help of great folks, I was able to pull off the task and the design was updated. &lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://docs.meshery.io&quot; alt=&quot;Meshery Documentation&quot;&gt;&lt;img src=&quot;static/mesheryctl-docs-859bc4ba845ff2038916a47482464756.png&quot; class=&quot;image-center-shadow&quot; alt=&quot;Meshery CLI command reference&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The redesign work was done with help of HTML in markdown and with optimization in YAML code. A sample is given below.&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&amp;lt;!-- Copy this template to create individual doc pages for each mesheryctl commands --&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &amp;lt;!-- Name of the command --&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    # mesheryctl mesh&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &amp;lt;!-- Description of the command. Preferably a paragraph --&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    ## Description&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    {% assign name = site.data.mesheryctlcommands.cmds[page.command] %}&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    {{ name.description }}&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;
&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &amp;lt;!-- Basic usage of the command --&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &amp;lt;pre class=&amp;quot;codeblock-pre&amp;quot;&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &amp;lt;div class=&amp;quot;codeblock&amp;quot;&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    mesheryctl mesh [flags] &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &amp;lt;/div&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &amp;lt;/pre&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    ...........&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;h3&gt;Adding auto generation feature in reference&lt;/h3&gt;&lt;p&gt;As time passed, we realized that the command reference missed something for a while, though the design has been changed. Then, we thought the idea of automating the generation of docs such that developers don&amp;#x27;t need to change the code in docs section while working towards &lt;code&gt;mesheryctl&lt;/code&gt;. That&amp;#x27;s where we got to know that Cobra library (the library for CLI apps made using golang) has a feature to make doc pages automatically. So we decided to incorporate that feature into &lt;code&gt;mesheryctl&lt;/code&gt; docs page as well! After making several changes and a PR, I was finally able to introduce the feature in the docs site!&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;var startCmd = &amp;amp;cobra.Command {&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    Use:   &amp;quot;start&amp;quot;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    Short: &amp;quot;Start Meshery&amp;quot;,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    Long:  `Start Meshery and each of its service mesh components.`,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    Args:  cobra.NoArgs,&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    Example: `&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;// Start meshery&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system start&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;// To create a new context for in-cluster Kubernetes deployments and set the new context as your current-context&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system context create k8s -p kubernetes -s&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;// (optional) skip checking for new updates available in Meshery.&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system start --skip-update&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;// Reset Meshery&amp;#x27;s configuration file to default settings.&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system start --reset&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;// Silently create Meshery&amp;#x27;s configuration file with default settings&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system start --yes&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;.....&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;}&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;19&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    `,&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Using this information provided above in each golang file, the markdown page is generated using Cobra CLI library and thus reducing the workload on the developer by automating via &lt;a href=&quot;https://github.com/meshery/meshery/blob/master/.github/workflows/mesheryctl-ci.yml#L73&quot;&gt;GitHub Actions&lt;/a&gt;.&lt;/p&gt;&lt;br/&gt;&lt;p&gt;This is so far on how the &lt;code&gt;mesheryctl&lt;/code&gt; command reference is evolved for now. And I hope that it&amp;#x27;ll continue to evolve in the field of documentation to serve the users to use Meshery in best way possible.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Istio Authorization Policy]]></title><link>https://layer5.io/resources/service-mesh/istio-authorization-policy</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/istio-authorization-policy</guid><pubDate>Wed, 01 Jun 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/731763d720780a49c2ffdfede8c28f4b/istio.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 sfJrc&quot;&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;Istio is a massive project with a wide range of capabilities and deployment options. We will learn about the Istio’s authorization policy with an example .&lt;/p&gt;&lt;/div&gt;&lt;p&gt;&lt;h2&gt;Let’s see Istio’s Security Architecture &lt;/h2&gt;&lt;/p&gt;&lt;p&gt;Before we directly jump into Istio&amp;#x27;s Authorization policies let&amp;#x27;s have a glance at Istio&amp;#x27;s Security architecture. The below diagram is directly referenced from Istio documentation. From the control plane, users can create things like authorization policies authentication policies, and policies will get translated into envoy config and streamed bent the varied proxies that form up the service mesh, on the information plane side there is east-west traffic from service b to c and also the actual communication takes place through sidecar proxies. If the traffic is entering it moves to the Ingress gateway and if it’s leaving it can attend the Egress gateway in between all this we will apply JWT enforcements.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;static/istio-securityarch-48cc1d41d8816131a3bf66bd55fd78df.svg&quot; align=&quot;center&quot; alt=&quot;comparative spectrum&quot;/&gt;&lt;/p&gt;&lt;h2&gt; Istio includes a high-level architecture that involves multiple factors such as:&lt;/h2&gt;&lt;p&gt;&lt;ul&gt;&lt;li&gt;  Certificate Authority for key and certificate management &lt;/li&gt;&lt;li&gt; Sidecar and perimeter proxies work as Policy Enforcement Points to secure communication between the clients and servers. &lt;/li&gt;&lt;li&gt; A set of Envoy proxy extensions is there to manage telemetry and auditing &lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;&lt;h2&gt; Istio’s Authorization policies&lt;/h2&gt;&lt;p&gt;&lt;ul&gt;&lt;li&gt;  Workload-to-workload and end-user-to-workload authorization. &lt;/li&gt;&lt;li&gt; A Simple API includes one single Authorization Policy, which is easy to use and maintain.&lt;/li&gt;&lt;li&gt;Flexible semantics: operators can define custom conditions on Istio attributes, and use DENY and permit actions. &lt;/li&gt;&lt;li&gt;  High performance: Istio authorization gets enforced natively on the Envoy. &lt;/li&gt;&lt;li&gt; High compatibility: supports gRPC, HTTP, HTTPS, and HTTP2 natively, additionaly as well as any plain TCP protocols. &lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;&lt;h2&gt;Example Authorization Policy&lt;/h2&gt;&lt;p&gt;In this example, we allow access to our service httpbin in namespace foo from any JWT (regardless of the principle) to use the GET method.&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;apiVersion: &amp;quot;security.istio.io/v1beta1&amp;quot;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;kind: &amp;quot;AuthorizationPolicy&amp;quot;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;metadata:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  name: &amp;quot;allow-reads&amp;quot;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  namespace: foo&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;spec:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  selector:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    matchLabels:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      app: httpbin&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  rules:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  - from:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    - source:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;        principals: [&amp;quot;*&amp;quot;]&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    to:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    - operation:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;        methods: [&amp;quot;GET&amp;quot;]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;h2&gt;Access Flow with Auth Policies&lt;/h2&gt;&lt;p&gt;There is some logic behind how authorization is set given defined AuthorizationPolicies. Below is that the flow as taken directly from the Istio documentation.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;If there are any CUSTOM policies that match the request, evaluate and deny the request if the evaluation result&amp;#x27;s is deny.&lt;/li&gt;&lt;li&gt;If there are any DENY policies that match with the request, deny the request.&lt;/li&gt;&lt;li&gt;If there are not any ALLOW policies for the workload, allow the request.&lt;/li&gt;&lt;li&gt;If any of the ALLOW policies gets match with the request, allow the request.&lt;/li&gt;&lt;li&gt;Deny the request.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Debug Envoy Proxy]]></title><description><![CDATA[An open index for measuring performance of cloud native infrastructure in context of the value provided to your business.]]></description><link>https://layer5.io/blog/envoy/debug-envoy-proxy</link><guid isPermaLink="false">https://layer5.io/blog/envoy/debug-envoy-proxy</guid><dc:creator><![CDATA[Layer5 Team]]></dc:creator><pubDate>Fri, 27 May 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/da5d909604f7704bb30151391b60cdbb/debug-envoy-proxy.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ZvKDg&quot;&gt;&lt;p&gt;Trying to figure out what&amp;#x27;s happening with your request traffic? Not sure why your Envoy configuration isn&amp;#x27;t working? If you&amp;#x27;re using Istio as your gateway and need to troubleshoot your ingress traffic requests, here are a few tips for debugging Envoy proxy.&lt;/p&gt;&lt;h2&gt;Enable Envoy Debug Logging&lt;/h2&gt;&lt;p&gt;By default Envoy system logs are sent to &lt;code&gt;/dev/stderr&lt;/code&gt;. This location be overridden using &lt;code&gt;--log-path&lt;/code&gt;. Logging to &lt;code&gt;/dev/stderr&lt;/code&gt;  for system logs and to &lt;code&gt;/dev/stdout&lt;/code&gt; for access logs can be useful when running Envoy inside a container. In this way, these two individual logstreams can be separated, and using this approach, logging requires no additional files or directories to be mounted.&lt;/p&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;We recommend setting the Envoy proxy’s log level to debug in a pre-production environment. Debug logs can help you identify issues before you graduate the associated configuration to your production environment.&lt;/p&gt;&lt;/div&gt;&lt;h3&gt;Using envoy CLI&lt;/h3&gt;&lt;p&gt;The envoy command has a &lt;code&gt;--log-level&lt;/code&gt; flag that can be useful for debugging. By default, it’s set to info. To change it to debug, edit the envoy DaemonSet in the istio-system namespace and replace the &lt;code&gt;--log-level info&lt;/code&gt; flag with &lt;code&gt;--log-level debug&lt;/code&gt;. Setting the Envoy log level to debug can be particilarly useful for debugging TLS connection failures.&lt;/p&gt;&lt;h3&gt;Using container image&lt;/h3&gt;&lt;p&gt;If you’re using the Envoy image, you can set the log level to debug through the &lt;code&gt;ENVOY_LOG_LEVEL&lt;/code&gt; environment variable. The log level for Envoy system logs can be set using the &lt;code&gt;-l&lt;/code&gt; or &lt;code&gt;--log-level&lt;/code&gt; option.&lt;/p&gt;&lt;p&gt;The available log levels are:&lt;/p&gt;&lt;ul&gt;&lt;li class=&quot;highlight&quot; style=&quot;width:fit-content&quot;&gt;trace&lt;/li&gt;&lt;li class=&quot;highlight&quot; style=&quot;width:fit-content&quot;&gt;debug&lt;/li&gt;&lt;li class=&quot;highlight&quot; style=&quot;width:fit-content&quot;&gt;info&lt;/li&gt;&lt;li class=&quot;highlight&quot; style=&quot;width:fit-content&quot;&gt;warning/warn&lt;/li&gt;&lt;li class=&quot;highlight&quot; style=&quot;width:fit-content&quot;&gt;error&lt;/li&gt;&lt;li class=&quot;highlight&quot; style=&quot;width:fit-content&quot;&gt;critical&lt;/li&gt;&lt;li class=&quot;highlight&quot; style=&quot;width:fit-content&quot;&gt;off&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The default is &lt;span class=&quot;highlight&quot;&gt;info&lt;/span&gt;.&lt;/p&gt;&lt;h3&gt;Setting Envoy logs in the Helm configuration&lt;/h3&gt;&lt;p&gt;The Consul helm chart uses &lt;code&gt;envoyExtraArgs:&lt;/code&gt; to leverage Envoy command line options. One of the helpful options is &lt;code&gt;--component-log-level&lt;/code&gt;. This provides granular control over setting log levels for Envoy components. In the example below, the components upstream, http, router and config are set to the debug log level. These four components are vital when debugging issues with requests between your services(sidecar proxies).&lt;/p&gt;&lt;div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;connectInject: enabled: true envoyExtraArgs: &amp;quot;--component-log-level upstream:debug,http:debug,router:debug,config:debug&amp;quot;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you haven&amp;#x27;t set envoyExtraArgs: in consul-values.yaml just yet, you can set the log levels on the fly by using the following kubectl command:&lt;/p&gt;&lt;div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$ kubectl exec pod/pod-name -c container-name -- curl -X POST http://localhost:19000/logging?config=debug&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$ kubectl exec pod/static-client-5bf4575d9c-zr2b -c static-client -- curl -X POST  http://localhost:19000/logging?config=debug&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You will execute the kubectl command for each component. Make sure to append the correct component at the end of the curl command, i.e. &lt;code&gt;logging? component = debug&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;If curl is not able to be used in your pod, you can alternatively use &lt;code&gt;kubectl port-forward pod-name 19000&lt;/code&gt; to make the Envoy admin accessible. From another terminal window, you can then curl to change the log levels. The output you receive in the terminal will show the modified component log levels.&lt;/p&gt;&lt;div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$ curl -X POST http://localhost:19000/logging? component = debug&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;Access Envoy logs in Kubernetes&lt;/h3&gt;&lt;p&gt;Accessing Envoy logs via pods can be done with the following command:&lt;/p&gt;&lt;div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$ kubectl logs --follow pod/ pod-name -c envoy-sidecar&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The --follow flag provides a real time observation into Envoy logs. &lt;/p&gt;&lt;h3&gt;Setting and Accessing Envoy logs when not using Helm.&lt;/h3&gt;&lt;p&gt;The following command will start an envoy side car proxy, set the log level to debug with -l debug and capture Envoy logs in envoy_logs.txt. The .txt file will need to be created before executing this command.&lt;/p&gt;&lt;div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$ consul connect envoy -sidecar-for counting-1 -- -l debug --log-path envoy_logs.txt&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To have granular control over the Envoy components that is needed to be debugged, use the following command:&lt;/p&gt;&lt;div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$ consul connect envoy -sidecar-for counting-1 -- --log-path envoy_logs.txt --component-log-level upstream:debug,http:debug,router:debug,config:debug&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;Find your Istio Ingress Gateway&lt;/h2&gt;&lt;p&gt;With Istio as your gateway, you should first look at &lt;code&gt;VirtualService&lt;/code&gt; objects. These can show if the hosts are registered to the gateway correctly.&lt;/p&gt;&lt;div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$ kubectl get virtualservice -o=yaml&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;However, sometimes, the &lt;a class=&quot;highlight&quot; href=&quot;https://envoyproxy.io&quot;&gt;Envoy&lt;/a&gt; inside the gateway container is not properly configured (likely due to a bug). You can dump Envoy configuration to debug this further.&lt;/p&gt;&lt;div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;# find istio ingress gateway pod \ $ kubectl get pods -n istio-system -l app=istio-ingressgateway&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;#x27;s use &lt;code&gt;istio-ingressgateway-a93019f9dfw-l39xd&lt;/code&gt; as an example pod name.&lt;/p&gt;&lt;div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;# enable debugging on envoy \ $ kubectl exec --namespace=istio-system \ istio-ingressgateway-a93019f9dfw-l39xd \ -c istio-proxy -- curl -X POST \ http://localhost:15000/logging?level=debug&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then, use &lt;code&gt;istioctl&lt;/code&gt; tool to dump route configuration (this will show the output from the &lt;a href=&quot;https://www.envoyproxy.io/docs/envoy/latest/operations/admin#operations-admin-interface-config-dump&quot;&gt;&lt;code&gt;/config_dump&lt;/code&gt; admin endpoint&lt;/a&gt; on Envoy):&lt;/p&gt;&lt;div&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 XqrAp&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 hdXkEl prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 bFANTz&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;$ istioctl proxy-config routes -n istio-system -o=json \ istio-ingressgateway-a93019f9dfw-l39xd&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We hope these steps are useful to you. If you&amp;#x27;re still having trouble configuring Envoy proxy, open up a new thread on the &lt;a href=&quot;https://discuss.layer5.io&quot; class=&quot;highlight&quot;&gt;community discussion forum&lt;/a&gt; or subscribe to the &lt;a class=&quot;highlight&quot; href=&quot;/subscribe&quot;&gt;Layer5 newletter&lt;/a&gt; for tips and tricks.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Intel, Layer5 Announce MeshMark to Quantify Cloud-Native Performance]]></title><link>https://layer5.io/company/news/intel-layer5-announce-meshmark-to-quantify-cloud-native-performance</link><guid isPermaLink="false">https://layer5.io/company/news/intel-layer5-announce-meshmark-to-quantify-cloud-native-performance</guid><dc:creator><![CDATA[ITPro Today]]></dc:creator><pubDate>Sat, 21 May 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/cd26e6a56aa3660f4a4295aad7b6612b/it-pro.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 lbnsvn&quot;&gt;&lt;div class=&quot;test&quot;&gt;&lt;p&gt;The open source Service Mesh Performance project is getting a new metric called MeshMark to help organizations manage and measure cloud-native environments. In cloud-native environments, the use of service mesh technologies to connect different operations is a growing trend. What isn&amp;#x27;t always clear with a service mesh though is how well it&amp;#x27;s actually working.&lt;/p&gt;&lt;p&gt;MeshMark, an open source effort jointly announced by Intel and service mesh startup Layer5 on May 18, looks to help organizations measure and quantify the performance and value of a service mesh deployment. MeshMark is part of the Service Mesh Performance project at the Cloud Native Computing Foundation (CNCF), which hosted its ServiceMeshCon EU event on May 18, co-located alongside KubeCon EU 2022.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re missing some performance characteristics,&amp;quot; Lee Calcote, founder and CEO of Layer5 and co-chair of the CNCF Technical Advisory Group (TAG) Network, said during a ServiceMeshCon EU session. &amp;quot;We have a need for a clear and concise way of conveying the characters and the performance of an environment.&amp;quot;&lt;/p&gt;&lt;h3&gt;MeshMark Brings Metrics to Cloud-Native Service Mesh&lt;/h3&gt;&lt;p&gt;The Service Mesh Performance project at its core is an effort to define specifications for capturing the details of a cloud-native environment in a uniform and consistent way, according to Calcote. In cloud-native environments, the use of service mesh technologies to connect different operations is a growing trend. What isn&amp;#x27;t always clear with a service mesh though is how well it&amp;#x27;s actually working.&lt;/p&gt;&lt;p&gt;MeshMark, an open source effort jointly announced by Intel and service mesh startup Layer5 on May 18, looks to help organizations measure and quantify the performance and value of a service mesh deployment. MeshMark is part of the Service Mesh Performance project at the Cloud Native Computing Foundation (CNCF), which hosted its ServiceMeshCon EU event on May 18, co-located alongside KubeCon EU 2022.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re missing some performance characteristics,&amp;quot; Lee Calcote, founder and CEO of Layer5 and co-chair of the CNCF Technical Advisory Group (TAG) Network, said during a ServiceMeshCon EU session. &amp;quot;We have a need for a clear and concise way of conveying the characters and the performance of an environment.&amp;quot;&lt;/p&gt;&lt;p&gt;The Service Mesh Performance project looks at capturing infrastructure and service mesh configuration details and then providing a means to characterize the details of running workloads. The project also aims to provide the details in a consistent approach that can enable organizations to develop a baseline for an environment, as well as benchmark in a consistent way. Simply being aware of what&amp;#x27;s running in a service mesh isn&amp;#x27;t quite enough though, and there is a need for a performance metric, which is where the new MeshMark effort comes into play. Mrittika Ganguli, principal engineer and network architect at Intel, explained that MeshMark is a cloud-native value measurement.&lt;/p&gt;&lt;p&gt;&amp;quot;With MeshMark, you&amp;#x27;re essentially trying to measure if the performance of your infrastructure matches what kind of business value you want to get from your deployment,&amp;quot; Ganguli said.&lt;/p&gt;&lt;p&gt;A business value could be defined with key performance indicators on, for example, how well video gets loaded on a particular webpage, she said.&lt;/p&gt;&lt;p&gt;&amp;quot;If you click on something, you may often see the text get rendered first and then the video,&amp;quot; Ganguli said. &amp;quot;The load latency of the video traffic is what impacts what you see visually.&amp;quot;&lt;/p&gt;&lt;p&gt;MeshMark aims to provide metrics that an organization can use to determine how resources are being used. Ganguli said that in a cloud-native environment an organization is utilizing different kinds of resources. The utilization classes include, for example, compute or network or any other type of resource.&lt;/p&gt;&lt;p&gt;MeshMark provides an efficiency metric called Mesh Utilization Efficiency (MUE) that can help determine a score for a given resource utilization and the level of optimization. The MeshMark score will be able to help identify what the load latency is for a given workload, given the available resources. Overall, the goal with MeshMark is to take a number of different signals coming from a service mesh and combine them into an approach that can help organizations understand how well a deployment is, or isn&amp;#x27;t, working.&lt;/p&gt;&lt;p&gt;The need to better understand the performance of service meshes was further underscored by a report released on May 17 by the CNCF. The report found that 60% of surveyed organizations are using a service mesh in production today — and that key challenges for deployment of service meshes are a lack of guidance, blueprints, and best practices.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[MeshMark: Cloud Native Value Measurement]]></title><description><![CDATA[An open index for measuring performance of cloud native infrastructure in context of the value provided to your business.]]></description><link>https://layer5.io/blog/service-mesh-performance/meshmark-cloud-native-value-measurement</link><guid isPermaLink="false">https://layer5.io/blog/service-mesh-performance/meshmark-cloud-native-value-measurement</guid><dc:creator><![CDATA[Gaurav Chadha]]></dc:creator><pubDate>Tue, 17 May 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/e99ce4e56d7c6d41ab1ba10000d406a7/banner.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ZvKDg&quot;&gt;&lt;div class=&quot;intro &quot;&gt;&lt;p&gt;&lt;a href=&quot;/community/members/lee-calcote&quot;&gt;Lee Calcote&lt;/a&gt; and &lt;a aria-current=&quot;page&quot; class=&quot;&quot; href=&quot;/&quot;&gt;Mrittika Ganguli&lt;/a&gt; presented &lt;i&gt;MeshMark: Service Mesh value measurement&lt;/i&gt; at ServiceMeshCon Europe 2022.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&quot;/community/members/lee-calcote&quot;&gt;Lee Calcote&lt;/a&gt; is an innovative product and technology leader, passionate about empowering engineers and enabling organizations. As the founder and CEO of Layer5, he is at the forefront of the cloud native movement.&lt;a aria-current=&quot;page&quot; class=&quot;&quot; href=&quot;/&quot;&gt; Mrittika Ganguli&lt;/a&gt; is the Director Cloud Native Data Plane, Principle Engineer and Network Architect at Intel.&lt;/p&gt;&lt;img src=&quot;data:image/svg+xml;base64,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&quot; alt=&quot;Developers need to access service mesh&quot; style=&quot;display:block;margin:0 auto 0.5rem;width:40%&quot;/&gt;&lt;p&gt;&lt;h2&gt;What is Meshmark?&lt;/h2&gt;&lt;/p&gt;&lt;p&gt;MeshMark is a performance index that measures the value and overhead of your cloud native environment. By converting performance measurements into insights about the value of individual, cloud native application networking functions, MeshMark distills a variety of overhead signals and key performance indicators into a simple index.&lt;/p&gt;&lt;img src=&quot;static/performance-question-4550370aff882cabe3f362660cbec90c.png&quot; alt=&quot;Developers need to access service mesh&quot; style=&quot;width:50%;css-float:right&quot;/&gt;&lt;p&gt;&lt;h3&gt;Talk started with a question to audience: Missing performance characteristics?&lt;/h3&gt;&lt;/p&gt;&lt;p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-9kzfnh-0 jHeMvO blockquote pull-left&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote&quot;&gt;&lt;h4&gt;We are missing some performance characteristics, as people has many metrics used to track environments it might take a while to articulate the characteristics performance of your environment.&lt;/h4&gt;&lt;h5 class=&quot;person&quot;&gt;Lee Calcote&lt;/h5&gt;&lt;h5 class=&quot;title&quot;&gt;&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;&lt;h3&gt;Lee Calcote explains about &amp;quot;Business Performance&amp;quot;&lt;/h3&gt;&lt;p&gt;We&amp;#x27;re quite frequently overlooking business performance, which is in large respect to why we&amp;#x27;re running the infrastructure in the first place. We usually talk about performance and cold, hard, quantitative speeds and feeds, but instead, I would submit to you that performance should absolutely be measured in terms of speeds and feeds, but it&amp;#x27;s a lot more meaningful to layer in the value and to quantify the value that your infrastructure is providing. So we&amp;#x27;re really kind of missing the business performance aspects of what we&amp;#x27;re tracking, how we&amp;#x27;re characterizing.&lt;/p&gt;&lt;img src=&quot;static/smp-in-meshery-6d6670922291e90b030f1b684fbcef04.png&quot; alt=&quot;Developers need to access service mesh&quot; style=&quot;width:50%;css-float:right&quot;/&gt;&lt;h3&gt;Introduction to Service Mesh Performance&lt;/h3&gt;&lt;p&gt;The Service Mesh Performance project falls under the umbrella of CNCF project. This project is, at its core, probably a specification for capturing the details of your environment in a uniform way, in a consistent way, capturing your infrastructure configuration, your service mesh configuration, and characterizing the details of your workloads and doing so consistently such that you can baseline your environments. You can benchmark them in a consistent way, share with others, maybe compare with the performance that others are having. To the extent that it&amp;#x27;s codified, you can have system to system exchange of this information.&lt;/p&gt;&lt;h2&gt;Mrittika Ganguli introduces MeshMark with an example&lt;/h2&gt;&lt;p&gt;MeshMark is a Cloud Native value measurement, from value you are essentially trying to measure if the performance of your infrastructure matches what you want to get from your deployment, what kind of value you want to get, business value you want to get from your deployment. So, for example, if you have some key performance indicators, do you want to measure whether the MeshMark value is directly responsible for how your video gets loaded or your image gets loaded on a particular webpage.&lt;p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-9kzfnh-0 jHeMvO blockquote pull-right&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote&quot;&gt;&lt;h4&gt;Are my resources utilized as best as possible? Why am I not getting the SLO met with 4 resources when I only needed 1 resource without the service mesh? How can I improve my 99.9% latencies or can I map my service policy to utilization? Is the network a performance hog, or storage, or cache? Meshmark intends to help model and provide an index for many of these areas&lt;/h4&gt;&lt;h5 class=&quot;person&quot;&gt;Mrittika Ganguli&lt;/h5&gt;&lt;h5 class=&quot;title&quot;&gt;&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;So often you see when you have a YouTube video uploaded, it will have only the text and not the video.&lt;/p&gt;And so what happens is you do not want that kind of an experience. You want the video to be and the images to be loaded first. As you can see in video if you click on something, you may often see the text get rendered first and then the video. The load latency of the video traffic is what impacts you see visually. And so the deployment of your cloud native environment. If it can be indexed through a MeshMark ratio, your load latency will be directly proportional to that and then the number of resources you&amp;#x27;re using to deploy this environment to get a particular lower latency or a higher latency is a usage metric and that&amp;#x27;s directly proportional to your MeshMark. The TCO of your application hence becomes directly related to MeshMark.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;static/meshmark-ce4c1c7718f5d4c0f463893b9d684644.png&quot; class=&quot;slides&quot; align=&quot;center&quot; style=&quot;margin-left:30px&quot; alt=&quot;meshmark&quot;/&gt;&lt;img src=&quot;static/example-a6699a7e68533bdee99cda9e50d062e7.png&quot; class=&quot;slides&quot; align=&quot;center&quot; style=&quot;margin-left:30px&quot; alt=&quot;meshmark example&quot;/&gt;&lt;/p&gt;&lt;img src=&quot;static/formula-9463eab12bc87207be26a97cbdc4f59a.png&quot; alt=&quot;MeshMark formula&quot; style=&quot;width:50%;css-float:right&quot;/&gt;&lt;h2&gt;MeshMark The Formula&lt;/h2&gt;&lt;p&gt;MeshMark functions as a value performance index (a scale) to provide organizations  the ability to weigh the value of their service mesh versus the overhead of their service mesh and assess whether they are getting out of the mesh what they are “paying” for in it. MeshMark’s scoring system ranges from 0 to 100 and incorporates collections of resource utilization efficiency calculations, categorized into similar consumption classes.&lt;/p&gt;&lt;h3&gt;Mrittika explains MUE&lt;/h3&gt;&lt;p&gt;It&amp;#x27;s a calculation, combined ratio of measured platform resources to assign resources. If you&amp;#x27;re able to measure what your assigned resources are in whatever form and able to also monitor what&amp;#x27;s the used resources, you can have this ratio. So, for example, a very simple one is CPU performance.&lt;img src=&quot;static/mue-fbf6c99e916c72e710b3df3b70b9de98.png&quot; alt=&quot;MeshMark MUE&quot; style=&quot;width:50%;css-float:left;padding-right:1rem&quot;/&gt; And you would want to see if the CPU performance as a ratio to the available resources is a loss or a gain. So CPU performance, raw loss over total CPU is our MUE one. And that&amp;#x27;s just one minus CPU utilization over 100. That&amp;#x27;s a very simple ratio and if you see on the slide, the graph shows you that as the latency increases, your Mue lowers. And so that&amp;#x27;s a very good indicator that your efficiency of your infrastructure is not very good because your latencies are increasing as your QPS increases. So like this you can measure and create other MUEs. We will look at how you can visualize this within an environment and so let&amp;#x27;s look at the demonstration. So let&amp;#x27;s jump into a sibling CNCF project called Meshery. Meshery is a cloud native management plane. Users of Meshery can configure their Kubernetes deployments any and every service mesh as well as on board and off board their workloads onto any given mesh.&lt;/p&gt;&lt;img src=&quot;static/meshmark-score-f693046918d095fe4bae11e6d359049f.png&quot; alt=&quot;MeshMap demo&quot; style=&quot;width:40%;css-float:right&quot;/&gt;&lt;h3&gt;Lee demonstrates MeshMap with an example Consul application&lt;/h3&gt;&lt;p&gt;Let&amp;#x27;s take an example workload a  Consul application, load it into the visual designer, take a look at the service splitting functionality of console and note in this case we&amp;#x27;re assigning a weight of three when we can change that to four to derive its MeshMark which is a mesh utilization efficiency calculation of the efficiency by which that network function is being performed. We could also take a look at service intentions of console and examine the efficiency of that network function. Now that you&amp;#x27;ve seen the demo you want to go ahead and publish the results and call everyone to get together.&lt;/p&gt;&lt;div style=&quot;text-align:center&quot;&gt;&lt;iframe width=&quot;70%&quot; height=&quot;450px&quot; style=&quot;margin-right:1.5rem;margin-left:1.5rem&quot; src=&quot;https://www.youtube.com/embed/yvqn6ckO7BI&quot; title=&quot;YouTube video player&quot; frameBorder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;p style=&quot;font-style:italic;font-size:1rem;margin-left:1rem&quot;&gt;MeshMark in Meshery (an excerpt from ServiceMeshCon EU 2022 demo)&lt;/p&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Lee Calcote and Mrittika Ganguli covered all the concepts of SMP and MeshMark in this great talk. Learn more about MeshMark on the &lt;a href=&quot;https://meshery.io/service-mesh-interface&quot;&gt;Service Mesh Performance &lt;/a&gt;website.&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[MeshMark: the Cloud Native Value Measurement]]></title><description><![CDATA[Layer5, a provider of cloud native management software, announced today the general availability of the Meshery Docker Extension. Complementing Docker Desktop's role as the go-to Kubernetes environment for cloud native developers, the Meshery Docker Extension provides easy access to the next layer of cloud native infrastructure: service meshes. As an inaugural Docker Extensions Partner and a maker of industry-defining, cloud native software, Layer5’s integration of Meshery provides a visual pathway for existing Docker Compose applications to move into Kubernetes and onto any service mesh.]]></description><link>https://layer5.io/company/news/meshmark-the-cloud-native-value-measurement</link><guid isPermaLink="false">https://layer5.io/company/news/meshmark-the-cloud-native-value-measurement</guid><dc:creator><![CDATA[The Newsroom]]></dc:creator><pubDate>Tue, 17 May 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/a2e688df73ddab1e987df5c0523f3078/meshmark-dark-full.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 lbnsvn&quot;&gt;&lt;p&gt;VALENCIA, Spain (May 17th, 2022) - ServiceMeshCon EU /KubeCon EU - &lt;a href=&quot;https://smp-spec.io/meshmark&quot;&gt;MeshMark&lt;/a&gt; is a performance index that measures the &lt;i&gt;value&lt;/i&gt; and &lt;i&gt;overhead&lt;/i&gt; of your cloud native environment. By converting performance measurements into insights about the value of individual, cloud native application networking functions, MeshMark distills a variety of overhead signals and key performance indicators into a simple index to facilitate quick and common comprehension.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-1yeq4hm-0 gQPXKP blockquote pull-right&quot; title=&quot;Vice President Cyber Cloud Security Engineering at Fiserv&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote-container&quot;&gt;&lt;h1 class=&quot;blockquote-quote&quot;&gt;Performance measurement data rarely provides a clear and simple picture of how well our applications are performing from a business point of view, which are so often the key efficiency indicators that we really need&lt;/h1&gt;&lt;h4 class=&quot;blockquote-person&quot;&gt;—Ken Owens&lt;/h4&gt;&lt;h5 class=&quot;blockquote-title&quot;&gt;Vice President Cyber Cloud Security Engineering at Fiserv&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;A wall of performance metrics causes confusion, not clarity.&lt;/p&gt;&lt;img src=&quot;static/meshmark-score-f693046918d095fe4bae11e6d359049f.png&quot; alt=&quot;MeshMark in Layer5 MeshMap&quot; width=&quot;40%&quot;/&gt;&lt;p&gt;By specifying a uniform way to analyze and report on the degree to which measured performance provides business value, MeshMark converts these metrics into insights about the efficiency and value of the functions your cloud native infrastructure is providing to your applications and services.&lt;/p&gt;&lt;h2&gt;Service Mesh Performance, the project&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;/company/news/cncf-adopts-service-mesh-performance-standard-established-by-layer5&quot;&gt;Adopted by the Cloud Native Computing Foundation (CNCF)&lt;/a&gt; in October of 2021, &lt;a href=&quot;/projects/service-mesh-performance&quot;&gt;Service Mesh Performance&lt;/a&gt; is an open source standard for service mesh efficiency, a growing consideration for cloud native operators and developers utilizing a service mesh in their infrastructure. With the myriad service meshes available and their sophisticated configurations, distributed systems efficacy and performance management is a continuous concern.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-9kzfnh-0 jHeMvO blockquote&quot; title=&quot;Chief Open Source Officer, Isovalent and Emeritus Chair of the CNCF’s TOC&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote&quot;&gt;&lt;h4&gt;Many cloud native adopters have been put off from using service mesh due to the extra resource consumption and complexity that it can involve. We welcome MeshMark as an objective measure of that overhead, to help drive efficiency and make it easier for users to compare service mesh options.&lt;/h4&gt;&lt;h5 class=&quot;person&quot;&gt;Liz Rice&lt;/h5&gt;&lt;h5 class=&quot;title&quot;&gt;Chief Open Source Officer, Isovalent and Emeritus Chair of the CNCF’s TOC&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;With project maintainers from Layer5, Intel, HashiCorp, and Red Hat, and collaborators from Isovalent, Buoyant, and FiServ, Service Mesh Performance is a vendor neutral cloud native performance measurement standard.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-1yeq4hm-0 gQPXKP blockquote&quot; title=&quot;CEO of Buoyant and one of the creators of Linkerd&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote-container&quot;&gt;&lt;h1 class=&quot;blockquote-quote&quot;&gt;While speed is one of Linkerd&amp;#x27;s core competitive advantages, Linkerd provides much more than just an ultrafast data plane. We are pleased to support MeshMark&amp;#x27;s establishment of a higher order set of functional considerations that incorporate value into the performance equation.&lt;/h1&gt;&lt;h4 class=&quot;blockquote-person&quot;&gt;—William Morgan&lt;/h4&gt;&lt;h5 class=&quot;blockquote-title&quot;&gt;CEO of Buoyant and one of the creators of Linkerd&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;With the project’s &lt;a href=&quot;/company/news/analyzing-service-mesh-performance&quot;&gt;approach to performance analysis&lt;/a&gt; published in IEEE The Bridge, ongoing analysis of nearly 40,000 performance test results will comprise the initial release of the &lt;a href=&quot;https://smp-spec.io/dashboard&quot;&gt;Service Mesh Performance Dashboard&lt;/a&gt;, also unveiling at KubeCon EU. &lt;a href=&quot;/cloud-native-management/meshery&quot;&gt;Meshery&lt;/a&gt;, the cloud native manager, orchestrates the provisioning and configuration of Kubernetes and each service mesh. With &lt;a href=&quot;/projects/nighthawk&quot;&gt;Nighthawk&lt;/a&gt; embedded, Meshery’s performance management functions are what drives the tests run within the CNCF Lab.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-9kzfnh-0 jHeMvO blockquote&quot; style=&quot;display:block&quot; title=&quot;Principal Engineer at Red Hat&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote&quot;&gt;&lt;h4&gt;The precision by which performance measurements are generated and analyzed is a pinnacle focus of Nighthawk. Mesh performance characterization should be distilled from a set of value measurements, and that is where MeshMark compliments to create the ultimate comprehensive efficiency calculation.&lt;/h4&gt;&lt;h5 class=&quot;person&quot;&gt;Otto van der Schaaf&lt;/h5&gt;&lt;h5 class=&quot;title&quot;&gt;Principal Engineer at Red Hat&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2&gt;MeshMark, the formula&lt;/h2&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-9kzfnh-0 jHeMvO blockquote pull-right&quot; title=&quot;Principal Engineer &amp;amp; Director Cloud Native Network Pathfinding&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote&quot;&gt;&lt;h4&gt;Are my resources utilized as best as possible? Why am I not getting the SLO met with 4 resources when I only needed 1 resource without the service mesh? How can I improve my 99.9% latencies or can I map my service policy to utilization? Is the network a performance hog, or storage, or cache? MeshMark will model and provide an index in answer to such questions.&lt;/h4&gt;&lt;h5 class=&quot;person&quot;&gt;Mrittika Ganguli&lt;/h5&gt;&lt;h5 class=&quot;title&quot;&gt;Principal Engineer &amp;amp; Director Cloud Native Network Pathfinding&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;MeshMark functions as a value performance index (a scale) to provide organizations the ability to weigh the value of their service mesh versus the overhead of their service mesh and assess whether they are getting out of the mesh what they are “paying” for in it. MeshMark’s scoring system ranges from 0 to 100 and incorporates collections of resource utilization efficiency calculations, categorized into similar consumption classes.&lt;/p&gt;&lt;img src=&quot;static/MeshMark-Formula-2d9704dfd0fe98f83e65c69f644fffd5.png&quot; alt=&quot;MeshMark Formula&quot;/&gt;&lt;p&gt;A Mesh Utilization Efficiency (MUE) is a calculated, combined ratio of specific infrastructure resource utilizations to assigned resources to cloud native infrastructure.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-1yeq4hm-0 gQPXKP blockquote&quot; title=&quot;Founder and CEO of Layer5, and Co-Chair of the CNCF TAG Network&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote-container&quot;&gt;&lt;h1 class=&quot;blockquote-quote&quot;&gt;A sophisticated, but simply communicated value-performance index, MeshMark, redefines efficiency utilization, bringing business, application, and infrastructure KPIs under a single unit of measure.&lt;/h1&gt;&lt;h4 class=&quot;blockquote-person&quot;&gt;—Lee Calcote&lt;/h4&gt;&lt;h5 class=&quot;blockquote-title&quot;&gt;Founder and CEO of Layer5, and Co-Chair of the CNCF TAG Network&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Learn how we distill a variety of microarchitecture performance signals and application key performance indicators into a simple measurement scale. Join the open source effort and explore the other side of the performance measurement coin: &lt;i&gt;value measurement&lt;/i&gt;.&lt;/p&gt;&lt;div&gt;&lt;iframe width=&quot;100%&quot; height=&quot;315&quot; style=&quot;margin-right:1.5rem;margin-left:1.5rem&quot; src=&quot;https://www.youtube.com/embed/yvqn6ckO7BI&quot; title=&quot;YouTube video player&quot; frameBorder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;p style=&quot;font-style:italic;font-size:1rem;margin-left:1rem&quot;&gt;MeshMark in Meshery (an excerpt from ServiceMeshCon EU 2022 demo)&lt;/p&gt;&lt;/div&gt;&lt;h4&gt;Resources&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;Attend &lt;a href=&quot;/community/events/servicemeshcon-eu-2022&quot;&gt;MeshMark: the Cloud Native Value Measurement&lt;/a&gt; presentation at ServiceMeshCon EU 2022.&lt;/li&gt;&lt;li&gt;Attend &lt;a href=&quot;/community/events/kubecon-cloudnativecon-eu-virtual-2022&quot;&gt;CNCF Tag Network and Service Mesh Working Group Deep Dive&lt;/a&gt; at KubeCon EU 2022. &lt;/li&gt;&lt;li&gt;Subscribe to the &lt;a href=&quot;https://smp-spec.io/subscribe&quot;&gt;project newsletter&lt;/a&gt; and engage in the &lt;a href=&quot;https://discuss.layer5.io/&quot;&gt;discussion forum&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;Learn more about &lt;a href=&quot;https://smp-spec.io/meshmark&quot;&gt;MeshMark&lt;/a&gt; on the &lt;a href=&quot;https://smp-spec.io&quot;&gt;Service Mesh Performance&lt;/a&gt; website.&lt;/li&gt;&lt;li&gt;Follow &lt;a href=&quot;https://twitter.com/smp_spec&quot;&gt;@smp_spec&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/mesheryio&quot;&gt;@mesheryio&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/layer5&quot;&gt;@layer5&lt;/a&gt; on Twitter.&lt;/li&gt;&lt;/ul&gt;&lt;h5&gt;About Layer5, Inc.&lt;/h5&gt;&lt;p style=&quot;font-size:1rem&quot;&gt;Layer5 offers cloud native application management by harnessing the unique position service meshes have in changing how developers write applications, how operators run modern infrastructure and how product owners manage their service offerings. For more information, visit &lt;a aria-current=&quot;page&quot; class=&quot;&quot; href=&quot;/&quot;&gt;layer5.io&lt;/a&gt;&lt;/p&gt;&lt;h5&gt;About Service Mesh Performance&lt;/h5&gt;&lt;p style=&quot;font-size:1rem&quot;&gt;Hosted within the CNCF, &lt;a href=&quot;/projects/service-mesh-performance&quot;&gt;Service Mesh Performance&lt;/a&gt; is a vendor-neutral cloud native performance measurement standard. Based on SMP, MeshMark provides a universal performance index to gauge your cloud native infrastructure’s efficiency and value. Visit &lt;a href=&quot;https://smp-spec.io/&quot;&gt;smp-spec.io&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Extending the Docker Compose Experience to Service Mesh]]></title><description><![CDATA[DockerCon 2022 talk with HashiCorp and MeshMap Demo]]></description><link>https://layer5.io/blog/docker/extending-the-docker-compose-experience-to-service-mesh</link><guid isPermaLink="false">https://layer5.io/blog/docker/extending-the-docker-compose-experience-to-service-mesh</guid><dc:creator><![CDATA[Gaurav Chadha]]></dc:creator><pubDate>Tue, 10 May 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/7916ca29f1b77dc315e26135210d9810/DC22-talk-HashiCorp.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ZvKDg&quot;&gt;&lt;div class=&quot;intro &quot;&gt;&lt;p&gt;&lt;a href=&quot;/community/members/lee-calcote&quot;&gt;Lee Calcote&lt;/a&gt; and &lt;a href=&quot;/community/members/nic-jackson&quot;&gt;Nic Jackson&lt;/a&gt; gave a presentation entitled &lt;i&gt;Extending the Docker Compose Experience to Service Mesh&lt;/i&gt; at DockerCon 2022.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;The &lt;a href=&quot;/docker-extension-meshery&quot;&gt;Meshery Docker Extension&lt;/a&gt; extends Docker Desktop&amp;#x27;s position as the cloud native developer&amp;#x27;s go-to Kubernetes environment with easy access to the next layer of cloud native infrastructure: service meshes.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;/community/members/lee-calcote&quot;&gt;Lee Calcote&lt;/a&gt; is an innovative product and technology leader, passionate about empowering engineers and enabling organizations. As the founder and CEO of Layer5, he is at the forefront of the cloud native movement.&lt;a href=&quot;/community/members/nic-jackson&quot;&gt; Nic Jackson &lt;/a&gt; is a developer advocate at HashiCorp, and the author of “Building Microservices in Go”, a book which examines the best patterns and practices for building microservices with the Go. Nic is also a coauthor of the Service Mesh Patterns book.&lt;/p&gt;&lt;p&gt;Nic Jackson has been using Docker Desktop from long time and tells how Docker Desktop provides feasibility to run Kubernetes for his local environment, while Lee Calcote recalls how Docker Desktop has become a staple of his daily routine while building an extension for Meshery.&lt;/p&gt;&lt;p&gt;&lt;h3&gt;Discussing Developers need to access Service Mesh&lt;/h3&gt;&lt;img src=&quot;static/developers-need-2403ae3372bb8becd55276b4f8d87746.png&quot; alt=&quot;Developers need to access service mesh&quot; style=&quot;width:50%;css-float:right&quot;/&gt;&lt;/p&gt;&lt;p&gt;Moving forward with the introduction to Docker Extension for Meshery, Nic says, &amp;quot;When it comes to Service Mesh, should developers care about Service Mesh? And the answer is Yes because developers need service mesh because of the changing reliability patterns implementation rapidly, it provides a tight feedback loop for developing and deploying workloads onto your service mesh and makes the over developer experience smooth. With the help of service, mesh developers should be able to create environments without needing to be operational experts.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;h3&gt;Meshery Extension offers an easy single click button to go from Docker comopose to Kubernetes to Service Mesh&lt;/h3&gt;&lt;img src=&quot;static/docker-extension-meshery-3239561a85c601cd913c9506c8a976f0.png&quot; alt=&quot;Docker Desktop Extension Meshery&quot; style=&quot;width:50%;css-float:right&quot;/&gt;&lt;/p&gt;&lt;p&gt;The Docker Extension for Meshery provides:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Service mesh support for your Docker Compose apps - Import your Docker Compose apps. Configure and deploy them to Kubernetes and any service mesh.&lt;/li&gt;&lt;li&gt;Visual designer for Docker Compose apps - Early access to the Docker Extension for Meshery that offers a visual topology for designing Docker Compose applications, operating Kubernetes, service meshes, and their workloads.&lt;/li&gt;&lt;li&gt;Single-click deployment of any service mesh - Support of 10 different service meshes to the fingertips of developers in connection with Docker Desktop’s ability to deliver Kubernetes locally.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;static/dashboard-eae1c9f2c39358245191393cf2d30e89.png&quot; alt=&quot;Docker Desktop Extension Meshery Dashboard&quot; style=&quot;width:50%;css-float:left;padding-right:30px&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;ul&gt;&lt;li&gt;While giving the demo Meshery Lee explained how with Docker Desktop running and Meshery extension installed we can see that Meshery has discovered the installed service mesh automatically and it performs action with the adapter present.&lt;/li&gt;&lt;li&gt;Meshery is a multi kubernetes cluster capable of performing lifecycle management of kubernetes as well as 10 different service meshes.&lt;/li&gt;&lt;li&gt;We can configure different service mesh based on their configurations and performs actions such as deploy, design, and explore all of the capabilities of service mesh via a rich schema with a live preview.&lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;&lt;h3&gt;Lee Calcote introduces MeshMap&lt;/h3&gt;&lt;/p&gt;&lt;img src=&quot;static/designer-1-e32642f89b561f0dc7fb9747ac062329.png&quot; alt=&quot;MeshMap Designer&quot; style=&quot;width:50%;css-float:right&quot;/&gt;MeshMap is the world&amp;#x27;s only visual designer for Kubernetes and service mesh deployments. Use MeshMap to design, deploy, and manage your Kubernetes-based, service mesh deployments. As a plugin for Meshery, MeshMap supports 10+ service meshes. MeshMap not only allows you to create and verify your cloud native application and infrastructure configurations, but also integrates with Meshery&amp;#x27;s service mesh catalog. It is a visual designer for developers to explore this same functionality. Lee showed example of Consul Service Mesh and performs different actions on it. Discussnig about the&lt;strong&gt; Designer Mode&lt;/strong&gt; It can design a service mesh deployment with application and Envoy filter from scratch. Customize a service mesh deployment with application and Envoy filter from pattern.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;static/viz-1-ad01b72fdbcf0e6e8dc13a7793d6843c.png&quot; alt=&quot;MeshMap Designer&quot; style=&quot;width:50%;css-float:left;padding-right:30px&quot;/&gt;The &lt;strong&gt;Visualizer Mode&lt;/strong&gt; examine a visual topology of Kubernetes cluster and its services. View and search log streams from your pod&amp;#x27;s containers. Connect an interactive terminal to instances of your containers.&lt;/p&gt;&lt;p&gt;To Lee&amp;#x27;s demo, Nic also added in the context of developer experience that MeshMap also makes it easy to do the job and with Meshery extension it makes it super easy to write and configure code without being worried for the developer environment.&lt;/p&gt;&lt;p&gt;These Docker Extensions are so powerful that it allows you to do multiple tasks without leaving Docker Desktop.&lt;/p&gt;&lt;div class=&quot;iframe-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/3DPZafR8VWM&quot; loading=&quot;lazy&quot; title=&quot;YouTube video player&quot; frameBorder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Lee Calcote and Nic Jackson packed a great deal of information in this talk. Find the recording below. The Meshery Extension is now out! Try now, and Share your Experience &lt;/strong&gt;&lt;a href=&quot;/meshmap&quot;&gt;Apply for MeshMap Beta Program&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</content:encoded></item></channel></rss>